"""
RobotGalaxyLibrary keywords
We have updated keywords as per Pyvmomi
library which is offical library from vmware
There are few keywords which are yet to be updated,
these are partially working, so we have comment those keywords :
"""
import atexit
import os
import os.path
from pyVim.connect import SmartConnectNoSSL, Disconnect
from pyVmomi import vim, vmodl
import re
from RoboGalaxyLibrary.version import VERSION
from RoboGalaxyLibrary.utilitylib import logging as logger
from sgmllib import SGMLParser
import shutil
from six.moves.urllib.request import build_opener, HTTPPasswordMgrWithDefaultRealm, HTTPBasicAuthHandler, \
    install_opener, Request, urlopen     # pylint: disable=import-error
import ssl
import sys
import tarfile
from threading import Timer
import time
import urllib2
import OpenSSL

# Python 2.7.9+ has issues with unverified certs. this is a workaround
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    # Legacy Python that doesn't verify HTTPS certificates by default
    pass
else:
    # Handle target environment that doesn't support HTTPS verification
    ssl._create_default_https_context = _create_unverified_https_context
# end workaround

_version_ = VERSION


class VsphereKeywords(object):
    """
    Custom Robot Framework keyword object
    """
    ROBOT_LIBRARY_SCOPE = 'Global'

    def __init__(self):
        """
        Object initializer method
        """
        self.service_instance = None
        self.content = None

    def connect_to_vi_server(self, ip, username, password, port=443):
        """
        Connect to a VI Server, returns connection object

        Example:
        | Connect to a VI Server | 10.15.14.3 | Administrator | Password
        """
        try:
            self.service_instance = SmartConnectNoSSL(host=ip,
                                                      user=username,
                                                      pwd=password,
                                                      port=port)
            atexit.register(Disconnect, self.service_instance)
            self.content = self.service_instance.RetrieveContent()
        except:     # no-qa
            logger.warn("Unable to connect to {}".format(ip))
            return False

        return True

    def vi_server_should_be_connected(self):
        """
        Ensure the VI server is connected
        Example:
        | VI Server Should Be Connected|
        """
        if not self.service_instance:
            raise AssertionError("VI Server should be connected.")
        return True

    def disconnect_from_vi_server(self):
        """
        Disconnect from VI Server,
        Example:
        | Disconnect From VI Server
        """
        Disconnect(self.service_instance)

    def power_on_vm(self, vm_name):
        """
        Power on a VM
        Example:
        Power On VM | myvmname |
        Returns: "success", AssertionError raised in case of failure.
        """
        return self.wait_for_task(self.get_obj([vim.VirtualMachine],
                                               vm_name).PowerOn())

    def power_off_vm(self, vm_name):
        """
        Power off a VM
        Example:
        Power Off VM | myvmname |
        Returns: "success", AssertionError raised in case of failure.
        """
        return self.wait_for_task(self.get_obj([vim.VirtualMachine],
                                               vm_name).PowerOff())

    def rename_vm(self, vm_name, new_vm_name):
        """
        Rename a VM
        Example:
        Rename VM | old_vm_name | new_vm_name|
        Returns: "success", AssertionError raised in case of failure.
        """
        return self.get_obj([vim.VirtualMachine], vm_name).Rename(new_vm_name)

    def reset_vm(self, vm_name):
        """
        Reset a VM
        Example:
        Reset VM | myvmname |
        Returns: "success", AssertionError raised in case of failure.
        """
        return self.wait_for_task(self.get_obj([vim.VirtualMachine],
                                               vm_name).Reset())

    def get_vm_memory(self, vm_name):
        """
        Get the vm memory in GB
        """
        return self.get_obj([vim.VirtualMachine],
                            vm_name).summary.config.memorySizeMB / 1024

    def get_vm_cpu(self, vm_name):
        """
        Get the vm cpu #
        """
        return self.get_obj([vim.VirtualMachine], vm_name).summary.config.numCpu

    def set_vm_memory(self, vm, memory_size):
        """
        Update the size of RAM for the VM in MB
        Example:
        Set VM Memory| myvmname | 16384
        Returns: "success", AssertionError raised in case of failure.
        """
        memory_size = long(memory_size)
        cspec = vim.vm.ConfigSpec()
        cspec.memoryMB = memory_size
        logger.info("Setting VM Memory size to {0}".format(memory_size))
        return self.wait_for_task(self.get_obj([vim.VirtualMachine],
                                               vm).Reconfigure(cspec))

    def set_vm_cpu(self, vm, num_cpus, num_cores_per_socket):
        """
        Set the CPU properties for the VM
        Example:
        Set VM CPU | myvmname | 2 | 4
        Returns: "success", AssertionError raised in case of failure.
        """
        num_cpus = int(num_cpus)
        num_cores_per_socket = int(num_cores_per_socket)
        cspec = vim.vm.ConfigSpec()
        cspec.numCPUs = num_cpus
        cspec.numCoresPerSocket = num_cores_per_socket
        logger.info("Setting VM virtual sockets to {}".format(num_cpus))
        _ = "Setting VM core per sockets to {}".format(num_cores_per_socket)
        logger.info(_)
        return self.wait_for_task(self.get_obj([vim.VirtualMachine],
                                               vm).Reconfigure(cspec))

    def suspend_vm(self, vm_name):
        """
        Suspend a VM
        Example:
        Suspend VM | myvmname |
        Retruns: "success", AssertionError raised in case of failure.
        """
        return self.wait_for_task(self.get_obj([vim.VirtualMachine],
                                               vm_name).Suspend())

    def get_vm_status(self, vm_name):
        """
        Provides VM PowerState
        Example:
        Get VM Status | myvmname | True |
        Returns: State such as POWERED ON', 'POWERED OFF', 'SUSPENDED',
                 'BLOCKED ON MSG'
        """
        return self.get_obj([vim.VirtualMachine], vm_name).runtime.powerState

    def get_vm_question(self, vm_name):
        """
        Returns a VM Question object with information about a question in this
        VM pending to be answered. None if the VM has no pending questions.
        Example:
        Get VM Question | myvmname |
        Returns: Text explaining VM question
        """
        return self.get_obj([vim.VirtualMachine], vm_name).runtime.question

    def get_vm_name_by_ip(self, vm_ip):
        """
        Get name of specified VM IP
        Example:
        Get VM Name By IP | 172.12.1.1 |
        Returns: string type, name of VM
        """
        return self.content.searchIndex.FindByIp(None, vm_ip,
                                                 True).summary.config.name

    def get_vms_in_folder(self, folder_name):
        """
        Get available VMs in specified folder
        Example:
        Get VMs Name in folder | myFolderName |
        Returns: List of VM
        """
        vm_names = None
        for child in self.content.rootFolder.childEntity:
            if hasattr(child, 'vmFolder'):
                datacenter = child
            else:
                continue
            for vm in datacenter.vmFolder.childEntity:
                if vm.name == folder_name:
                    vm_names = vm.childEntity
        return vm_names

    def is_vm_powered_off(self, vm_name):
        """
        Check VM is in powered off state or not
        Example:
        Is VM Powered Off | myvmname |
        Returns: Boolean value True or False
        """
        if self.get_obj([vim.VirtualMachine],
                        vm_name).runtime.powerState == "poweredOff":
            return True
        else:
            return False

    def is_vm_powered_on(self, vm_name):
        """
        Check VM is in Powered on state or not
        Example:
        Is VM Powered On | myvmname |
        Returns : Boolean True or False
        """
        if self.get_obj([vim.VirtualMachine],
                        vm_name).runtime.powerState == "poweredOn":
            return True
        else:
            return False

    def is_vm_suspended(self, vm_name):
        """
        Check VM is in suspended state or not
        Example:
        Is VM Suspended | myvmname |
        Returns : Boolean True or False
        """

        if self.get_obj([vim.VirtualMachine],
                        vm_name).runtime.powerState == "suspended":
            return True
        else:
            return False

    def reboot_vm_guest(self, vm_name):
        """
        Issues a command to the guest operating system asking it to perform
        a reboot. Returns immediately and does not wait for the guest operating
        system to complete the operation.
        Example:
        | Reboot VM Guest | myvmname |
        Returns : None
        """
        return self.wait_for_task(self.get_obj([vim.VirtualMachine],
                                               vm_name).RebootGuest())

    def shutdown_vm_guest(self, vm_name):
        """
        Issues a command to the guest operating system asking it to perform
        a clean shutdown of all services. Returns immediately and does not wait
        for the guest operating system to complete the operation.
        Example:
        | Shutdown Guest | myvmname |
        Returns: None
        """
        self.get_obj([vim.VirtualMachine], vm_name).ShutdownGuest()

    def create_vm_snapshot(
            self,
            vm_name,
            snapshot_name,
            description,
            memory=False,
            quiesce=True):
        """
        Create a VM snapshot
        Example:
        | Create VM Snapshot | myvmname | snapshotname | True | True |
        Returns: Success, Assertion error in case of failure
        """
        return self.wait_for_task(self.get_obj([vim.VirtualMachine],
                                               vm_name).CreateSnapshot(
            snapshot_name,
            description,
            memory,
            quiesce))

    def revert_vm_to_current_snapshot(self, vm):
        """
        Revert a VM to its current snapshot
        Example:
        Revert VM To Current Snapshot | myvmname |
        Returns: Success, Assertion error in case of failure
        """
        return self.wait_for_task(self.get_obj([vim.VirtualMachine],
                                               vm).RevertToCurrentSnapshot())

    def delete_named_vm_snapshot(self, vm_name, snapshot_name,
                                 remove_children=False):
        """
        Delete the VM's named snapshot
        Example:
        Delete Named VM Snapshot | myvmname | mysnapshotname | False |
        Returns: True, Raise Assertion error in case of failure
        """
        flag = False
        snapshots = self.get_obj([vim.VirtualMachine],
                                 vm_name).snapshot.rootSnapshotList
        # traverse from root snapshot to their respective child

        while len(snapshots) > 0:
            for child in range(0, len(snapshots)):
                if snapshots[child].name == snapshot_name:
                    snapshots[child].snapshot.RemoveSnapshot_Task(
                        remove_children)
                    flag = True
                    break
                if len(snapshots[child].childSnapshotList) < 1:
                    break
            snapshots = snapshots[0].childSnapshotList
        if flag:
            return flag
        else:
            raise AssertionError("Failed to find snapshot name %s" %
                                 snapshot_name)

    def destroy_vm(self, vm_name):
        """
        Delete the VM and files
        Example:
        Destroy VM | myvmname |
        Returns: Success, Raise Assertion error in case of failure
        """
        return self.wait_for_task(self.get_obj([vim.VirtualMachine],
                                               vm_name).Destroy_Task())

    def get_vm_ipv4_addresses(self, vm_name):
        """
        Get the VMs IP address(es)
        Example:
        Get VM IP | myvmname |
        Returns: List of IP
        """
        ip = []
        net_info = self.get_obj([vim.VirtualMachine], vm_name).guest.net
        for cur_net in net_info:
            for cur_ip in cur_net.ipConfig.ipAddress:
                if re.match(r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}',
                            cur_ip.ipAddress) and \
                        cur_ip.ipAddress != '127.0.0.1':
                    ip.append(cur_ip.ipAddress)
        return ip

    def get_vm_network_devices(self, vm_name):
        """
        Get the VMs device(es)
        Example:
        Get VM Network Devices | myvmname |
        Returns: List of device which contains key and value
        """
        devices = []
        net_info = self.get_obj([vim.VirtualMachine], vm_name).guest.net
        for cur_net in net_info:
            if cur_net.macAddress:
                devices.append({
                    'mac_address': cur_net.macAddress,
                    'network_name': cur_net.network
                })
        return devices

    def get_vm_device_mac_address(self, vm_name, device):
        """
        Get the VMs mac_address(es)
        Example:
        get_vm_device_mac_address | myvmname | 'Network adapter #'| myhost
        Returns: Mac address
        """
        for nic in self.getvmnics(vm_name):
            if nic['nic_number'] == device:
                return nic['mac_address']

        raise AssertionError("Specified adapter name %s not found" % device)

    def get_vm_ipv6_addresses(self, vm_name):
        """
        Get the VMs IP address(es)
        Example:
        Get VM IP | myvmname |
        Returns: List of ipv6
        """
        ipv6 = []
        net_info = self.get_obj([vim.VirtualMachine], vm_name).guest.net
        for cur_net in net_info:
            for cur_ip in cur_net.ipConfig.ipAddress:
                if re.match('.*:.*', cur_ip.ipAddress):
                    ipv6.append(cur_ip.ipAddress)
        return ipv6

    def _get_resource_pool(self, name):
        """
        Get the selected resource pool
        Example:
        Get Resource Pool | name|
        Returns: resource pool object
        """
        return self.get_obj([vim.ResourcePool], name)

    def _get_host(self, name):
        """
        Get the selected host
        Example:
        Get Host | Name |
        Returns: host object
        """
        return self.get_obj([vim.HostSystem], name)

    def _get_datacenter(self, name):
        """
        Returns the selected datacenter
        Example:
        Get Datacenter | Name |
        Returns: Datacenter object
        """
        dc_obj = self.get_obj([vim.Datacenter], name)
        if dc_obj is None:
            raise AssertionError("Failed to find datacenter: {}".format(name))

        return dc_obj

    def _get_cluster(self, cluster_name):
        """
        Returns the selected cluster
        Example:
        Get Cluster | Name |
        Returns: cluster object
        """
        for dc in self.content.rootFolder.childEntity:
            if hasattr(dc, 'vmFolder'):
                for cluster in dc.hostFolder.childEntity:
                    if cluster.name == cluster_name:
                        return cluster

        raise AssertionError("Failed to find cluster %s " % cluster_name)

    def _get_datastore(self, datastore_name, datacenter_name=None):
        """
        Get the instance of specified datastore name
        Example:
        Get Datastore |datastore1|DataCenter_path
        Returns: AssertionError  in case of failure.
        """
        dc_name = None
        if datacenter_name:
            dc_name = self._get_datacenter(datacenter_name)
            datastore = self.get_obj([vim.Datastore], datastore_name)
        else:
            datastore = self.content.searchIndex.FindChild(dc_name.datastoreFolder, datastore_name)

        if not datastore:
            raise AssertionError("Failed to find datastore %s " % datastore_name)

        return datastore

    def rename_datastore(self, datastore_name, new_datastore_name, datacenter_name=None):
        """
        Rename a datastore
        Example:
        Rename datastore | old_datastore_name | new_datastore_name| datacenter_name
        Returns: "success", AssertionError raised in case of failure.
        """
        return self._get_datastore(datastore_name, datacenter_name).Rename(new_datastore_name)

    def create_vm_guest(self, vm_settings):
        """
        Create VM guest on selected host
        Example:
        ${vm_settings}={datacenter=datacenterName, clusterName=clusterName,
                        guestname=VM1, guestmemory=2048, guestcpu=1,
                        guestdatastore=datastore, guestos=vm_os}
        Create VM Guest | vm_settings |
        Returns: Success, Assertion error in case of failure
        """
        datacenter_name = str(vm_settings['datacenter'])
        guest_name = str(vm_settings['guestname'])
        guest_mem = int(vm_settings['guestmemory'])
        guest_cpu = int(vm_settings['guestcpu'])
        guest_os = vm_settings.get('guestos')
        datastore_name = str(vm_settings['guestdatastore'])
        cluster_name = str(vm_settings['clusterName'])

        datastore_path = '[' + datastore_name + '] ' + guest_name
        datacenter = self._get_datacenter(datacenter_name)
        vm_folder = datacenter.vmFolder
        resource_pool = self.get_resource_pool(cluster_name)

        # bare minimum VM shell, no disks. Feel free to edit
        vmx_file = vim.vm.FileInfo(logDirectory=None, snapshotDirectory=None,
                                   suspendDirectory=None,
                                   vmPathName=datastore_path)
        config = vim.vm.ConfigSpec(name=guest_name, memoryMB=guest_mem,
                                   numCPUs=guest_cpu, files=vmx_file,
                                   version='vmx-07', guestId=guest_os)
        task = vm_folder.CreateVM_Task(config=config, pool=resource_pool)
        return self.wait_for_task(task)

    def get_distibuted_switch_port_group(self, datacentername):
        """
        Get the Distributed switch port group ID
        Example:
        Get Distributed Switch Port Group |Hydrogen_DS |
        Returns: List of  distibuted_switch_port_group
        """
        dspg = []
        datacenters = self.content.rootFolder.childEntity
        for datacenter in datacenters:
            if datacenter.name == datacentername:
                networks = datacenter.networkFolder.childEntity
                for network in networks:
                    if isinstance(network, vim.dvs.DistributedVirtualPortgroup):
                        dspg.append(network)
        return dspg

    def get_resource_pool(self, cluster_name, resource_pool_name=None):
        """
        Get the resource pool name, if there is no name provided it returns the
        root resource pool using Cluster name.

        Example:
        Get Resource Pool |ClusterName | ResourcePoolName
        Returns: resource pool name.
        """
        if not resource_pool_name:
            cluster = self.get_obj([vim.ClusterComputeResource], cluster_name)
            # use same root resource pool that my desired cluster uses
            return cluster.resourcePool
        else:
            return self._get_resource_pool(resource_pool_name)

    def create_datacenter(self, dcname=None, folder=None):
        """
        Creates a new datacenter with the given name.
        Example:
        Create Datacenter |DC Name|Folder|
        Returns: created datacneter
        """
        if len(dcname) > 79:
            raise ValueError("The datacenter name must be under 80 characters.")
        if folder is None:
            folder = self.service_instance.content.rootFolder

        if folder is not None and isinstance(folder, vim.Folder):
            dc_moref = folder.CreateDatacenter(name=dcname)
            return dc_moref

    def remove_datacenter(self, dcname):
        """
        Remove existing datacenter, returns Success if successfully removed
        otherwise throw error
        Example: Remove Datacenter | myDC|
        Returns: Success, Raise Assertion error in case of failure
        """
        dc_obj = self._get_datacenter(dcname)
        task = dc_obj.Destroy_Task()
        return self.wait_for_task(task)

    def disconnect_host(self, host_name):
        """
        The API takes the host connected to vcenter and disconnects such
        that it can be removed from cluster easily
        Disconnect host| Host_Name
        Returns: Success, Raise Assertion error in case of failure
        """
        return self.wait_for_task(self._get_host(host_name).DisconnectHost_Task())

    def create_cluster(self, cluster_name, datacenter_name, cluster_spec=None):
        """
        Create a Cluster in vCenter, if no cluster_spec provided, HA cluster
        will be created, with Host monitoring, failoverLevel 5, vm and
        app monitoring will be enabled by default.

        Example:
        Create Cluster |cluster_name |datacenter_name| cluster_spec|
        Returns: Instance of created cluster.
        """
        datacenter_name = self._get_datacenter(datacenter_name)
        if cluster_spec is None:
            cluster_spec = vim.cluster.ConfigSpecEx()
            config_info = vim.cluster.DasConfigInfo()
            config_info.enabled = True
            config_info.vmMonitoring = 'vmAndAppMonitoring'
            config_info.failoverLevel = 5
            config_info.admissionControlEnabled = False
            cluster_spec.dasConfig = config_info
        host_folder = datacenter_name.hostFolder
        cluster = host_folder.CreateClusterEx(name=cluster_name,
                                              spec=cluster_spec)

        return cluster

    def update_cluster(self, cluster_name, cluster_spec=None):
        """
        Update a Cluster in vCenter, if no cluster_spec provided, HA cluster
        will be updated, with Host monitoring, failoverLevel 10, vm monitoring
        will be enabled by default.

        Example:
        update Cluster |cluster_name |cluster_spec|
        Returns: Success, Raise Assertion error in case of failure
        """
        cluster_obj = self._get_cluster(cluster_name)
        if cluster_spec is None:
            cluster_spec = vim.cluster.ConfigSpec()
            das_config_info = vim.cluster.DasConfigInfo()
            das_config_info.enabled = True
            das_config_info.vmMonitoring = 'vmMonitoringOnly'
            das_config_info.failoverLevel = 10
            cluster_spec.dasConfig = das_config_info
        # Flag to specify whether the specification ("spec") should be applied
        # incrementally.
        task = cluster_obj.ReconfigureCluster_Task(cluster_spec, True)
        return self.wait_for_task(task)

    def rename_cluster(self, cluster_name, new_cluster_name):
        """
        Rename a Cluster
        Example:
        Rename Cluster | old_cluster_name | new_cluster_name|
        Returns: "success", AssertionError raised in case of failure.
        """
        return self._get_cluster(cluster_name).Rename(new_cluster_name)

    def get_hosts_in_cluster(self, cluster_name):
        """
        Returns hosts in cluster
        Example:
        get_hosts_in_cluster | cluster_name |
        """
        cluster_obj = self.get_obj([vim.ComputeResource], cluster_name)
        return [host.name for host in cluster_obj.host]

    def remove_cluster(self, cluster_name):
        """
        Remove existing cluster, returns Success if successfully removed
        otherwise throw error

        Example: Remove Cluster | Cluster Name|
        Returns: Success, Raise Assertion error in case of failure
        """
        cluster_obj = self._get_cluster(cluster_name)
        task = cluster_obj.Destroy_Task()
        return self.wait_for_task(task)

    def remove_host_in_cluster(self, cluster_name, host_name):
        """
        Remove host in cluster Returns None if specified host is not in the
        cluster.

        Example:
        Remove Host In Cluster | cluster_name | host_name |
        """
        cluster_obj = self.get_obj([vim.ComputeResource], cluster_name)
        task = [host.Destroy_Task()
                for host in cluster_obj.host if host.name == host_name]

        return next(iter(task), None)

    def add_host_to_cluster(self, host_name, cluster_name, user_name, password,
                            thumbprint, as_connected=True, resource_pool=None):
        """
        Adds a host to the cluster. The host name must be either an IP address,
        such as 192.168.0.1, or a DNS resolvable name

        Example:
        Add Host To Cluster | host_name | Cluster_Name | user_name | password |
        ...                   thumbprint |
        Returns: Success, Raise Assertion error in case of failure
        """
        cluster_obj = self._get_cluster(cluster_name)
        connect_spec = vim.host.ConnectSpec()
        connect_spec.hostName = host_name
        connect_spec.port = 443
        connect_spec.userName = user_name
        connect_spec.password = password
        connect_spec.sslThumbprint = thumbprint
        connect_spec.force = True
        if not resource_pool:
            task = cluster_obj.AddHost(connect_spec, as_connected)
        else:
            task = cluster_obj.AddHost(connect_spec, as_connected,
                                       resource_pool)
        return self.wait_for_task(task)

    def move_cluster_into_folder(self, cluster_name, folder_name):
        """
        Move a Cluster into folder
        Example:
        Move Cluster Into Folder | cluster_name | folder_name|
        Returns: "success", AssertionError raised in case of failure.
        """
        folder_obj = self.get_obj([vim.Folder], folder_name)
        if not folder_obj:
            raise AssertionError("Failed to find Folder %s " % folder_name)

        cluster_obj = self._get_cluster(cluster_name)
        return self.wait_for_task(folder_obj.MoveIntoFolder_Task([cluster_obj]))

    def create_host_folder(self, folder_name, dc_name):
        """
        Create a host and cluster Folder in vCenter

        Example:
        Create Host Folder |folder_name |datacenter_name|
        Returns: Instance of created folder.
        """
        return self._get_datacenter(dc_name).hostFolder.CreateFolder(folder_name)

    def remove_host_folder(self, folder_name, dc_name):
        """
        Remove Cluster & Host Folder from Datacenter

        Example: Remove Host Folder | folder_name|
        Returns: Success, Raise Assertion error in case of failure
        """
        datacenter_obj = self._get_datacenter(dc_name)
        searchIndex = self.content.searchIndex
        host_folder = searchIndex.FindChild(datacenter_obj.hostFolder, folder_name)
        if not host_folder:
            raise AssertionError("Failed to find Folder %s in DC - %s" % (folder_name, dc_name))

        return self.wait_for_task(host_folder.Destroy_Task())

    def get_all_objs(self, vimtype):
        """
        Gets all objects in the vcenter which are of type defined by 'vimtype'
        """
        vm = self.content.viewManager
        return vm.CreateContainerView(self.content.rootFolder, vimtype,
                                      True).view

    def get_all_hosts_and_uuid(self):
        """
        Returns list of dictionaries of all hosts and their UUIDs from the
        vcenter
        """
        hosts = self.get_all_objs([vim.HostSystem])
        if not hosts:
            return list()

        return [{'host': host.name,
                 'uuid': host.hardware.systemInfo.uuid} for host in hosts]

    def get_host_by_uuid(self, uuid):
        """
        find host by UIID and returns its hostname
        Example:
        get_host_by_uuid | uuid |
        """
        search_index = self.content.searchIndex
        host = search_index.FindByUuid(None, uuid, False, False)
        if not host:
            raise AssertionError("Unable to find host for uuid %s" % uuid)
        else:
            return host.name

    @staticmethod
    def get_host_ssl_thumbprint(host):
        """
        Gets the ssl thumbprint of the esxi host
        Example:
        Get Host SSL Thumbprint |host|
        """
        cert = ssl.get_server_certificate((host, 443))
        pem = OpenSSL.crypto.load_certificate(OpenSSL.crypto.FILETYPE_PEM, cert)
        return pem.digest('sha1')

    def add_host_to_datacenter_cluster(self, host_name, thumbprint,
                                       datacenter_name, cluster_name, user,
                                       password, as_connected=True):
        """
        Adds a host to the cluster of the given Datacenter.
        The host name must be either an IP address or a DNS resolvable name
        Example:
        Add Host To Datacenter Cluster | host |thumbprint |datacenter |cluster |
        ...                              user |password |
        """
        cluster_obj = None
        dc = self._get_datacenter(datacenter_name)
        if not dc:
            raise Exception('Unable to find datacenter: %s' % datacenter_name)
        else:
            clusters = dc.hostFolder.childEntity
            for cluster in clusters:
                if cluster.name == cluster_name:
                    cluster_obj = cluster
                    break

        if not cluster_obj:
            raise Exception('Unable to find the cluster: %s' % cluster_name)
        else:
            connect_spec = vim.host.ConnectSpec()
            connect_spec.hostName = host_name
            connect_spec.port = 443
            connect_spec.userName = user
            connect_spec.password = password
            connect_spec.sslThumbprint = thumbprint
            connect_spec.force = True
            task = cluster_obj.AddHost(connect_spec, as_connected)
            return self.wait_for_task(task)

    def add_host_to_vcenter(self, host_name, datacenter_name, user, password,
                            as_connected=True):
        """
        Adds a host to the given Datacenter in VCenter.
        host_name: ESXi server to be added to datacenter. It must be either an
                   IP address or a DNS resolvable name
        datacenter_name: Existing Datacenter on which ESXi server is to be added.
        user: username of ESXi server used to add the host to vcenter datacenter.
        password: password for the user on ESXi server provided as earlier argument
        Example:
        Add Host To Vcenter | host | datacenter | user | password |
        """
        dc_obj = self._get_datacenter(datacenter_name)
        if not dc_obj:
            raise AssertionError('Unable to find datacenter: %s' % datacenter_name)

        connect_spec = vim.host.ConnectSpec()
        connect_spec.hostName = host_name
        connect_spec.port = 443
        connect_spec.userName = user
        connect_spec.password = password
        connect_spec.sslThumbprint = self.get_host_ssl_thumbprint(host_name)
        connect_spec.force = True

        try:
            task = dc_obj.hostFolder.AddStandaloneHost(connect_spec,
                                                       addConnected=as_connected)
        except:
            raise AssertionError("Unable to add host to vCenter")

        return self.wait_for_task(task)

    def remove_host_from_datacenter(self, dc_name, host_name):
        """
        Removes a host from datacenter.
        Returns none if the host is not found in the datacenter
        Example:
        Remove Host From Datacenter | datacenter | host |
        """

        datacenter_obj = self._get_datacenter(dc_name)
        if not datacenter_obj:
            raise AssertionError('Unable to find datacenter: %s' % dc_name)
        else:
            task = [host.Destroy_Task()
                    for host in datacenter_obj.hostFolder.childEntity
                    if host.name == host_name]
            return self.wait_for_task(next(iter(task), None))

    def create_nasdatastore(self, host_name):
        """
        Method to create a NAS datastore on the provided ESXi host
        :param host_name: Name of the host
        :return:
        """
        if host_name is None:
            raise ValueError("Missing value for host_name.")

        host = self.get_obj([vim.HostSystem], host_name)
        spec = vim.host.VMFSVolume.Specification()
        spec.remoteHost = host_name
        spec.remotePath = "/vmfs/volumes"
        spec.localPath = "vcenter-nfs"
        spec.accessMode = "readWrite"

        return host.configManager.datastoreSystem.CreateVMFSDatastore(spec)

    def move_host_into_cluster(self, host_name, cluster_name,
                               resource_pool=None):
        """
        Moves an existing host into a cluster. The host must be part of the same
        datacenter, and if the host is part of a cluster, the host must be in
        maintenance mode. If the host is a stand-alone host, the stand-alone
        ComputeResource is removed as part of this operation

        Example:
        Move Host Into Cluster | Host_Name | Cluster_Name | Resource_pool|
        Returns: Success, Raise Assertion error in case of failure
        """
        host = self._get_host(host_name)
        cluster_obj = self._get_cluster(cluster_name)
        if not resource_pool:
            task = cluster_obj.MoveHostInto(host)
        else:
            resource = self._get_resource_pool(resource_pool)
            task = cluster_obj.MoveHostInto(host, resource)
        return self.wait_for_task(task)

    def shutdown_host(self, host_name, force=False):
        """
        shuttingdown an existing host,Host can be present in Datacenter or cluster
        Example:
        Shutdown Host | Host_Name | force |
        Returns: Success, Raise Assertion error in case of failure
        """
        if force:
            return self.wait_for_task(self._get_host(host_name).ShutdownHost_Task(force))

        raise AssertionError("Graceful shutdown of the host is not implemented")

    def enter_host_into_maintenance_mode(self, host_name, cluster_name=None,
                                         option=None, timeout=0):
        """
        The API takes a host in the cluster as input, and the server can successfully
        evacuate existing constraints in the cluster, such as HA, FT, Vmotion
        compatibility, reservations, affinity rules, etc. option
        (vim.option.OptionValue, optional):

        An array of `OptionValue`_ options for this query. The specified
        options override the advanced options in `ClusterDrsConfigInfo`_
        In case cluster is not passed, directly it will move host into maintenance mode.
        Example:
        Enter Host Into Maintenance Mode | Host_Name | Cluster_Name | Option |
        Returns: Success, Raise Assertion error in case of failure
        """
        host = [self._get_host(host_name)]
        if not cluster_name:
            return self.wait_for_task(host[0].EnterMaintenanceMode(timeout))
        cluster_obj = self._get_cluster(cluster_name)
        if not option:
            enter_maintenance_result = \
                cluster_obj.ClusterEnterMaintenanceMode(host)
        else:
            resource = self._get_resource_pool(option)
            enter_maintenance_result = \
                cluster_obj.ClusterEnterMaintenanceMode(host, resource)
        recommendations = enter_maintenance_result.recommendations
        for recommendation in recommendations:
            cluster_Action = recommendation.action
            if cluster_Action[0].type == "HostMaintenanceV1":
                return self.wait_for_task(cluster_Action[0].target.EnterMaintenanceMode(timeout))
        raise AssertionError('Unable to Move the host to maintenance: %s \n Please find the vcenter recommendations: %s' % (host_name, recommendations))

    def is_host_in_maintenance_mode(self, host):
        """
        Takes the Host Ip as Input and returns True if host is in Maintenance mode
        :param host:
        :return: True if Host is in Maintenance mode or else False
        Example:
        Is Host in Maintenance Mode | Host_Name |
        Rasies Assertion Error if the host is not found in the vcenter
        """
        host_obj = self._get_host(host)
        if host_obj is None:
            raise AssertionError('Unable to find the host in Vcenter: {0}'.format(host))

        return host_obj.runtime.inMaintenanceMode

    def host_should_be_in_maintenance_mode(self, host):
        """
        Validates if the host is in maintenance mode or not
        Example:
        Host Should Be In Maintenance Mode | host |
        Returns: Raise Assertion error in case host not in maintenance mode
        """
        if not self.is_host_in_maintenance_mode(host):
            raise AssertionError("{} is not in Maintenance Mode".format(host))

    def host_should_not_be_in_maintenance_mode(self, host):
        """
        Validates if the host is in maintenance mode or not
        Example:
        Host Should Not Be In Maintenance Mode | host |
        Returns: Raise Assertion error in case host not in maintenance mode
        """
        if self.is_host_in_maintenance_mode(host):
            raise AssertionError("{} is in Maintenance Mode".format(host))

    def get_host_power_state(self, host=None):
        """
        Takes the Host Ip as Input and returns powerState of host
        All possible powerState as given in rturn doc
        :param host:
        :return: poweredOff When Host is power off state.
                 poweredOn  The host is powered on.
                 standBy    The host was specifically put in standby mode.
                 unknown    If the host is disconnected, or notResponding.
        Example:
        Get Host Power State | Host_Name |
        Raises Assertion Error if the host is not found in Vcenter
        """
        host_obj = self.get_mor(name=host)
        if host_obj is None:
            raise AssertionError('Unable to find the host in Vcenter: {0}'.format(host))

        return host_obj.runtime.powerState

    def expected_power_state_of_host(self, expected_power_state, host=None):
        """
        Validates the host powerState with actual power state and expected power state
        Example:
        Expected Power State Of Host | expected_power_state | host |
        All possible values for expected_power_state is poweredOff,  poweredOn, standBy, unknown
        Raises Assertion Error if Invalid expected_power_state is passed
        Raises Assertion Error if the host is not in expected_power_state
        """
        host_actual_power_state = self.get_host_power_state(host)
        valid_host_power_state_list = ["poweredOff", "poweredOn", "standBy", "unknown"]

        if expected_power_state not in valid_host_power_state_list:
            raise AssertionError(
                "Unsupported power state: {}\nSupported power states: {}".format(expected_power_state,
                                                                                 valid_host_power_state_list))

        if expected_power_state != host_actual_power_state:
            raise AssertionError(
                "Host: {} is expected to be in {} where as host is in {}".format(host, expected_power_state,
                                                                                 host_actual_power_state))

    def change_vm_network(self, vm_name, network_to):
        """
        Change the network of vm
            vm_name: Name of the vm
            network_to :  new network name
        Example:
        change_vm_network    ${DCS NAME}      vlan1000-10.0.x.x
        Returns: Success, Raise Assertion error in case of failure
        """
        vm = self.get_obj([vim.VirtualMachine], vm_name)
        # This code is for changing only one Interface. For multiple Interface
        # Iterate through a loop of network names.
        device_change = []
        for device in vm.config.hardware.device:
            if isinstance(device, vim.vm.device.VirtualEthernetCard):
                nicspec = vim.vm.device.VirtualDeviceSpec()
                nicspec.operation = \
                    vim.vm.device.VirtualDeviceSpec.Operation.edit
                nicspec.device = device
                nicspec.device.wakeOnLanEnabled = True
                network = self.get_obj([vim.dvs.DistributedVirtualPortgroup],
                                       network_to)

                dvs_port_connection = vim.dvs.PortConnection()
                dvs_port_connection.portgroupKey = network.key
                dvs_port_connection.switchUuid = network.config.distributedVirtualSwitch.uuid
                nicspec.device.backing = vim.vm.device.VirtualEthernetCard.DistributedVirtualPortBackingInfo()
                nicspec.device.backing.port = dvs_port_connection

                nicspec.device.connectable = \
                    vim.vm.device.VirtualDevice.ConnectInfo()
                nicspec.device.connectable.startConnected = True
                nicspec.device.connectable.allowGuestControl = True
                device_change.append(nicspec)
                break

        config_spec = vim.vm.ConfigSpec(deviceChange=device_change)
        task = vm.ReconfigVM_Task(config_spec)
        self.wait_for_task(task)

    def add_network_adapter_to_vm(self, vm_name, net_name, dvs=None):
        """
        Add Network Adapter to vm
            vm_name: Name of the vm
            net_name :  name of the the network
            dvs : Type of network we are adding, if we are creating dvs network
                  then pass any non empty value such as True.
        Example:
        Add_Network_Adapter_To_vm   | VM Name| Net Name |True
        Returns: Success, Raise Assertion error in case of failure
        """
        devices = []
        vm = self.get_obj([vim.VirtualMachine], vm_name)
        nic = vim.vm.device.VirtualDeviceSpec()
        # or edit if a device exists
        nic.operation = vim.vm.device.VirtualDeviceSpec.Operation.add
        # nic.device = vim.vm.device.VirtualVmxnet3()
        nic.device = vim.vm.device.VirtualE1000()
        nic.device.wakeOnLanEnabled = True
        nic.device.deviceInfo = vim.Description()
        nic.device.deviceInfo.label = net_name
        nic.device.deviceInfo.summary = net_name
        nic.device.addressType = 'assigned'
        nic.device.connectable = vim.vm.device.VirtualDevice.ConnectInfo()
        nic.device.connectable.startConnected = True
        nic.device.connectable.allowGuestControl = True

        if not dvs:
            nic.device.backing = \
                vim.vm.device.VirtualEthernetCard.NetworkBackingInfo()
            nic.device.backing.network = self.get_obj([vim.Network], net_name)
            nic.device.backing.deviceName = net_name
        else:
            network = self.get_obj([vim.dvs.DistributedVirtualPortgroup],
                                   net_name)
            dvs_port_connection = vim.dvs.PortConnection()
            dvs_port_connection.portgroupKey = network.key
            dvs_port_connection.switchUuid = \
                network.config.distributedVirtualSwitch.uuid
            nic.device.backing = vim.vm.device.VirtualEthernetCard.DistributedVirtualPortBackingInfo()
            nic.device.backing.port = dvs_port_connection

        devices.append(nic)
        vmconf = vim.vm.ConfigSpec(deviceChange=devices)
        task = vm.ReconfigVM_Task(vmconf)
        return self.wait_for_task(task)

    def assign_ip_to_vm(self, vm_name, net_details, isWindows=None, isDHCP=None):
        """
        Assign IP to vm
        Data example
        ${new_ipaddress}    10.32.2.200
        ${subnetmask}       255.255.0.0
        ${domain}           dom1032.net
        ${gateway}          10.32.0.1
        ${dnsserver}        10.32.0.11
        ${dnsserver33}      10.33.0.11
        @{lstdnsserver}     ${dnsserver}
        @{net1}             ${new_ipaddress}    ${subnetmask}    ${gateway}
                            ${lstdnsserver}    ${domain}
        @{net2}             10.33.2.100         ${subnetmask}    10.33.0.1
                            10.33.0.11    dom1033.net
        @{net_details}      ${net1}    ${net2}
        assign_ip_to_network    ${vm_name}    ${net_details}
        Example:
        Assign IP TO Network|VM Name| Net Details
        Returns: Success, Raise Assertion error in case of failure
        """
        lst = []
        vm = self.get_obj([vim.VirtualMachine], vm_name)
        if vm.runtime.powerState != 'poweredOff':
            _ = "WARNING:: Power off your VM before reconfigure Vm Name="
            _ += ' {}'.format(vm_name)
            raise AssertionError(_)

        # guest NIC settings, i.e. "adapter map"
        globalip = vim.vm.customization.GlobalIPSettings()
        customspec = vim.vm.customization.Specification()
        for net in net_details:
            adaptermap = vim.vm.customization.AdapterMapping()
            adaptermap.adapter = vim.vm.customization.IPSettings()
            if not isDHCP:
                """Static IP Configuration"""
                adaptermap.adapter.ip = vim.vm.customization.FixedIp()
                adaptermap.adapter.ip.ipAddress = net[0]
                adaptermap.adapter.subnetMask = net[1]
                adaptermap.adapter.gateway = net[2]
                globalip.dnsServerList = net[3][0]
            else:
                """DHCP Configuration"""
                adaptermap.adapter.ip = vim.vm.customization.DhcpIpGenerator()
            adaptermap.adapter.dnsDomain = net[4]
            lst.append(adaptermap)

        # For Linux . For windows follow sysprep
        # ident = vim.vm.customization.LinuxPrep(domain=domain,
        # hostName=vim.vm.customization.FixedName(name=vm_name))

        ident = vim.vm.customization.Sysprep()
        ident.guiUnattended = vim.vm.customization.GuiUnattended()

        # windows
        if not isWindows:
            ident.userData = vim.vm.customization.UserData()
            ident.userData.computerName = vim.vm.customization.FixedName()
            ident.userData.computerName.name = vm_name
            ident.userData.fullName = vm_name
            ident.identification = vim.vm.customization.Identification()
            ident.userData.orgName = "HPE"
        customspec.identity = ident
        customspec.nicSettingMap = lst
        customspec.globalIPSettings = globalip

        task = vm.Customize(spec=customspec)
        return self.wait_for_task(task)

    def migrate_vm_to_another_resource_pool(self, vm_name, resourcepool):
        """
        Migrate vm to another resource pool
        Example:
        Migrate VM |name | resourcepool |
        Returns: Success, Raise Assertion error in case of failure
        """

        vm = self.get_obj([vim.VirtualMachine], vm_name)
        resource = self._get_resource_pool(resourcepool)
        relocate_spec = vim.vm.RelocateSpec(pool=resource)

        # does the actual migration to pool
        task = vm.Relocate(relocate_spec)
        return self.wait_for_task(task)

    def migrate_vm_host_and_datastore(self, vm_name, host_name, datastore_name):
        """
        migrate vm host and datastore
        Example:
           migrate vm host and datastore  |vm_name  |host_name  |datastore_name
        Returns: Success, Raise Assertion error in case of failure
        """

        vm = self.get_obj([vim.VirtualMachine], vm_name)
        datastorename = self._get_datastore(datastore_name)
        hostname = self._get_host(host_name)

        # relocate spec, to migrate to another host and datastore
        relocate_spec = vim.vm.RelocateSpec(host=hostname,
                                            datastore=datastorename)

        # does the actual migration to host
        return self.wait_for_task(vm.Relocate(relocate_spec))

    def migrate_vm_host(self, vm_name, host_name):
        """
        migrate vm host
        Example:
           Migrate VM Host|vm_name  |host_name
        Returns: Success, Raise Assertion error in case of failure
        """
        vm = self.get_obj([vim.VirtualMachine], vm_name)
        hostname = self._get_host(host_name)

        # relocate spec, to migrate to another host
        relocate_spec = vim.vm.RelocateSpec(host=hostname, datastore=None)

        # does the actual migration to host
        return self.wait_for_task(vm.Relocate(relocate_spec))

    def create_dvswitch_add_hosts(self, dvs_name, datacenter_name, *hosts):
        """
        Create dvswitch with provided hosts, datacenter_name, dvs and dv port
        name

        Example:
        Create Dvswitch Add hosts  |dvs_name|Datacenter_name |Hosts|
        Returns: Success, Raise Assertion error in case of failure
        """
        hosts_obj = []
        for host in hosts:
            hosts_obj.append(self._get_host(host))
        network_folder = self._get_datacenter(datacenter_name).networkFolder
        pnic_specs = []
        dvs_host_configs = []
        uplink_port_names = []
        dvs_create_spec = vim.DistributedVirtualSwitch.CreateSpec()
        dvs_config_spec = vim.DistributedVirtualSwitch.ConfigSpec()
        dvs_config_spec.name = dvs_name
        dvs_config_spec.uplinkPortPolicy = \
            vim.DistributedVirtualSwitch.NameArrayUplinkPortPolicy()

        # add host to dvswitch
        for x in range(len(hosts_obj)):
            uplink_port_names.append("dvUplink%d" % x)

        for host in hosts_obj:
            dvs_config_spec.uplinkPortPolicy.uplinkPortName = uplink_port_names
            dvs_config_spec.maxPorts = 2000
            pnic_spec = vim.dvs.HostMember.PnicSpec()
            pnic_spec.pnicDevice = 'vmnic1'
            pnic_specs.append(pnic_spec)
            dvs_host_config = vim.dvs.HostMember.ConfigSpec()
            dvs_host_config.operation = vim.ConfigSpecOperation.add
            dvs_host_config.host = host
            dvs_host_configs.append(dvs_host_config)
            dvs_host_config.backing = vim.dvs.HostMember.PnicBacking()
            dvs_host_config.backing.pnicSpec = pnic_specs
            dvs_config_spec.host = dvs_host_configs

        dvs_create_spec.configSpec = dvs_config_spec
        dvs_create_spec.productInfo = vim.dvs.ProductSpec(version='5.0.0')

        task = network_folder.CreateDVS_Task(dvs_create_spec)
        return self.wait_for_task(task)

    def dvswitch_should_exist(self, dvs_name):
        """
        dvswitch should exist will return true if dvswitch found
        Example:
        Dvswitch Should Exist |Dvs_name|
        Returns: True, Raise Assertion error in case dvswitch does not exist
        """
        dvs_obj = self.get_obj([vim.DistributedVirtualSwitch], dvs_name)
        if dvs_obj:
            return True
        else:
            _ = "Distributed virtual switch %s not found" % dvs_name
            raise AssertionError(_)

    def remove_dvswitch(self, dvs_name):
        """
        Remove Dvswitch Returns True on successful completion of task, raise
        assertion in case of failure.

        Example:
        Remove Dvswitch |Dvs_name|
        Returns: Success, Raise Assertion error in case of failure
        """
        dvs_obj = self.get_obj([vim.DistributedVirtualSwitch], dvs_name)
        task = dvs_obj.Destroy_Task()
        return self.wait_for_task(task)

    def add_dvport_group_to_dvswitch(self, dv_switch, dv_port_name):
        """
        add dvPort group to dvswitch
        Example:
        Add Dvport Group To Dvswitch |Dv_switch| DvPortName|
        Returns: Success, Raise Assertion error in case of failure
        """
        dv_switch = self.get_obj([vim.DistributedVirtualSwitch], dv_switch)
        dv_pg_spec = vim.dvs.DistributedVirtualPortgroup.ConfigSpec()
        dv_pg_spec.name = dv_port_name
        dv_pg_spec.numPorts = 32
        dv_pg_spec.type = \
            vim.dvs.DistributedVirtualPortgroup.PortgroupType.earlyBinding

        dv_pg_spec.defaultPortConfig = \
            vim.dvs.VmwareDistributedVirtualSwitch.VmwarePortConfigPolicy()
        dv_pg_spec.defaultPortConfig.securityPolicy = \
            vim.dvs.VmwareDistributedVirtualSwitch.SecurityPolicy()

        dv_pg_spec.defaultPortConfig.vlan = \
            vim.dvs.VmwareDistributedVirtualSwitch.TrunkVlanSpec()
        dv_pg_spec.defaultPortConfig.vlan.vlanId = [vim.NumericRange(start=1,
                                                                     end=4094)]
        dv_pg_spec.defaultPortConfig.securityPolicy.allowPromiscuous = \
            vim.BoolPolicy(value=True)
        dv_pg_spec.defaultPortConfig.securityPolicy.forgedTransmits = \
            vim.BoolPolicy(value=True)

        dv_pg_spec.defaultPortConfig.vlan.inherited = False
        dv_pg_spec.defaultPortConfig.securityPolicy.macChanges = \
            vim.BoolPolicy(value=False)
        dv_pg_spec.defaultPortConfig.securityPolicy.inherited = False

        return self.wait_for_task(dv_switch.AddDVPortgroup_Task([dv_pg_spec]))

    def add_scsi_controller_to_vm(self, vm_name):
        """
        Add scsi controller to vm
                vm_name: Name of the vm
        Example:
        add_scsi_controller_to_vm   | VM Name
        Returns: Success, Raise Assertion error in case of failure
        """
        devices = []
        vm = self.get_obj([vim.VirtualMachine], vm_name)
        controller = vim.vm.device.VirtualDeviceSpec()
        # or edit if a device exists
        controller.operation = vim.vm.device.VirtualDeviceSpec.Operation.add
        controller.device = vim.vm.device.VirtualLsiLogicSASController()
        controller.device.sharedBus = \
            vim.vm.device.VirtualSCSIController.Sharing.noSharing
        controller.device.connectable = \
            vim.vm.device.VirtualDevice.ConnectInfo()
        controller.device.connectable.startConnected = True
        controller.device.connectable.allowGuestControl = True

        devices.append(controller)
        vmconf = vim.vm.ConfigSpec(deviceChange=devices)
        task = vm.ReconfigVM_Task(vmconf)
        return self.wait_for_task(task)

    def add_disk(self, guest_name, disk_size, disk_type):
        """
        add disk to existing vm, vm should have atlease one disk
        Example:
        Add Disk | guest_name | disk_size | disk_type|
        Returns: Success, Raise Assertion error in case of failure
        """
        unit_number = 0
        vm = self.get_obj([vim.VirtualMachine], guest_name)
        spec = vim.vm.ConfigSpec()

        # get all disks on a VM, set unit_number to the next available
        controller = None
        for dev in vm.config.hardware.device:

            if hasattr(dev.backing, 'fileName'):
                unit_number = int(dev.unitNumber) + 1
                # unit_number 7 reserved for scsi controller
                if unit_number == 7:
                    unit_number += 1
                if unit_number >= 16:
                    logger.info("we don't support this many disks")
                    return
            if isinstance(dev, vim.vm.device.VirtualSCSIController):
                controller = dev
        # add disk here
        dev_changes = []
        new_disk_kb = int(disk_size) * 1024 * 1024
        disk_spec = vim.vm.device.VirtualDeviceSpec()
        disk_spec.fileOperation = "create"
        disk_spec.operation = vim.vm.device.VirtualDeviceSpec.Operation.add
        disk_spec.device = vim.vm.device.VirtualDisk()
        disk_spec.device.backing = \
            vim.vm.device.VirtualDisk.FlatVer2BackingInfo()
        if disk_type == 'thin':
            disk_spec.device.backing.thinProvisioned = True
        disk_spec.device.backing.diskMode = 'persistent'
        disk_spec.device.unitNumber = unit_number
        disk_spec.device.capacityInKB = new_disk_kb
        disk_spec.device.controllerKey = controller.key
        dev_changes.append(disk_spec)
        spec.deviceChange = dev_changes
        task = vm.ReconfigVM_Task(spec=spec)
        return self.wait_for_task(task)

    def expand_vmdisk(self, vm_name, disk_size):
        """
        Extend Harddisk Size
            vm_name: Name of the vm
            disk_size :  Disk Sizse

        Example:
        extend_harddisk_size    ${vm_name}      30
        Returns: Success, Raise Assertion error in case of failure
        """
        vm = self.get_obj([vim.VirtualMachine], vm_name)
        for dev in vm.config.hardware.device:
            if hasattr(dev.backing, 'fileName'):
                new_disk_kb = int(disk_size) * 1024 * 1024
                dev_changes = []
                disk_spec = vim.vm.device.VirtualDeviceSpec()
                disk_spec.operation = \
                    vim.vm.device.VirtualDeviceSpec.Operation.edit
                disk_spec.device = vim.vm.device.VirtualDisk()
                disk_spec.device.key = dev.key
                disk_spec.device.backing = \
                    vim.vm.device.VirtualDisk.FlatVer2BackingInfo()
                disk_spec.device.backing.fileName = dev.backing.fileName
                disk_spec.device.backing.diskMode = dev.backing.diskMode
                disk_spec.device.controllerKey = dev.controllerKey
                disk_spec.device.unitNumber = dev.unitNumber
                disk_spec.device.capacityInKB = new_disk_kb
                dev_changes.append(disk_spec)

                spec = vim.vm.ConfigSpec()
                spec.deviceChange = dev_changes

                task = vm.ReconfigVM_Task(spec=spec)
                return self.wait_for_task(task)

    def deploy_vm_template(self, template_name, vm_name, resourcepool=None,
                           datastore=None, power_on=True):
        """ Deploy a template to a VM
        Example:
        Deploy VM Template |template_name | resourcepool | datastore|
        Returns: Success, Raise Assertion error in case of failure
        """

        # Relocation spec
        relospec = vim.vm.RelocateSpec()
        relospec.datastore = self.get_obj([vim.Datastore], datastore)
        relospec.pool = self._get_resource_pool(resourcepool)

        # Clone spec
        clonespec = vim.vm.CloneSpec()
        clonespec.location = relospec
        clonespec.powerOn = power_on
        clonespec.template = False
        task = self.get_obj([vim.VirtualMachine],
                            template_name).Clone(folder=self.content.rootFolder.childEntity[0].vmFolder,
                                                 name=vm_name, spec=clonespec)
        return self.wait_for_task(task)

    def get_vm_hosts(self):
        """
        Getting all ESX hosts .
        Example:
        Get VM Hosts  |Contents|
        Returns: list of host instances
        """
        vm = self.content.viewManager
        host_view = vm.CreateContainerView(self.content.rootFolder,
                                           [vim.HostSystem], True)
        obj = [host for host in host_view.view]
        host_view.Destroy()
        return obj

    def getvmnics(self, vm):
        """
        Get vmnics of specified vm
        Example:
        Getvmnics |VmName|
        Returns: List of key and values {'mac_address': dev.macAddress,
                    'portGroup': port_group_name,
                    'nic_number': dev.deviceInfo.label,
                    'vSwitch': v_switch,
                    'VLan': vlan_id}
        """
        vm = self.get_obj([vim.VirtualMachine], vm)
        nics = []
        host = vm.runtime.host
        host_page_dict = self.get_hosts_port_groups(host)
        for dev in vm.config.hardware.device:
            if isinstance(dev, vim.vm.device.VirtualEthernetCard):
                dev_backing = dev.backing
                if hasattr(dev_backing, 'port'):
                    port_group_key = dev.backing.port.portgroupKey
                    dvs_uuid = dev.backing.port.switchUuid
                    try:
                        dvs = \
                            self.content.dvSwitchManager.QueryDvsByUuid(dvs_uuid)
                    except:     # no-qa
                        port_group_name = "** Error: DVS not found **"
                        vlan_id = "NA"
                        v_switch = "NA"
                    else:
                        port_group_obj = dvs.LookupDvPortGroup(port_group_key)
                        port_group_name = port_group_obj.config.name
                        vlan_id = str(port_group_obj.config.defaultPortConfig.vlan.vlanId)
                        v_switch = str(dvs.name)
                else:
                    port_group_name = dev.backing.network.name
                    pgs = host_page_dict[host]
                    for p in pgs:
                        if port_group_name in p.key:
                            vlan_id = str(p.spec.vlanId)
                            v_switch = str(p.spec.vswitchName)
                if port_group_name is None:
                    port_group_name = 'NA'
                nics.append({'mac_address': dev.macAddress,
                             'portGroup': port_group_name,
                             'nic_number': dev.deviceInfo.label,
                             'vSwitch': v_switch,
                             'VLan': vlan_id})

        return nics

    def get_hosts_port_groups(self, host):
        """
        Get hosts port groups
        Example:
        Get Hosts Port Groups | Hosts |
        Returns: dictionary of hosts port groups available on hosts
        """
        logger.info("Collecting portgroups on all hosts. This may take a while")
        host_page_dict = {}
        host = self.get_obj([vim.HostSystem], host)
        pgs = host.config.network.portgroup
        host_page_dict[host] = pgs
        logger.info("Host %s done." % host.name)
        logger.info("\tPortgroup collection complete.")
        return host_page_dict

    def get_obj(self, vimtype, name):
        """
        Get the vsphere object associated with a given text name
        """
        vm = self.content.viewManager
        for c in vm.CreateContainerView(self.content.rootFolder, vimtype,
                                        True).view:
            if c.name == name:
                return c

        return None

    @staticmethod
    def wait_for_task(task):
        """
        wait for a vCenter task to finish
        """
        task_done = False
        while not task_done:
            if task.info.state == 'success':
                return task.info.state
            if task.info.state == 'error':
                _ = "Failed to complete task, error = %s" % task.info.error
                raise AssertionError(_)

    @staticmethod
    def invoke_and_track(func, *args, **kw):
        """
        Invoke and monitor the function method
        :param func:
        :param args:
        :param kw:
        :return:
        """
        try:
            task = func(*args, **kw)
            return task
        except:         # no-qa
            raise AssertionError("Fail to track task")

    def create_vm_relocate_spec(self, **kwargs):
        """
        Creates a vim.RelocateSpec
        :param  note: none of these parameters are required. Only allowed
                      parameters for InstantCloneSpec are currently implemented.
                datastore:       string value of the target datastore name
                deviceChange:    *not implemented
                disk:            *not implemented
                diskMoveType:    *not implemented
                folder:          string value of the target folder name
                host:            string value of the target host name
                pool:            string value of the target resource pool name
                profile:         *not implemented
                service:         *not implemented
        :return: vim.vm.RelocateSpec
        """
        _ = 'not implemented in vsphere.py create_vm_relocate_spec()!'
        if 'datastore' in kwargs:
            kwargs['datastore'] = self._get_datastore(kwargs['datastore'])

        if 'deviceChange' in kwargs:
            logger.warn('deviceChange {}'.format(_))

        if 'disk' in kwargs:
            logger.warn('disk {}'.format(_))

        if 'diskMoveType' in kwargs:
            logger.warn('diskMoveType {}'.format(_))

        if 'folder' in kwargs:
            kwargs['folder'] = self.get_obj([vim.Folder], kwargs['folder'])

        if 'host' in kwargs:
            kwargs['host'] = self._get_host(kwargs['host'])

        if 'pool' in kwargs:
            kwargs['pool'] = self._get_resource_pool(kwargs['pool'])

        if 'profile' in kwargs:
            logger.warn('profile {}'.format(_))

        if 'service' in kwargs:
            logger.warn('service {}'.format(_))

        return vim.vm.RelocateSpec(**kwargs)

    def create_option_value(self, options):
        """
        see: https://pubs.vmware.com/vsphere-6-5/index.jsp
        ?topic=%2Fcom.vmware.vsan.apiref.doc%2Fvim.option.OptionValue.html
        :param options:  key\value pair of options to be set
        :return: vim.option.OptionValue
        """
        return [vim.option.OptionValue(key=k, value=v)
                for k, v in options.iteritems()]

    def create_vm_instant_clone_spec(self, spec):
        """
        Creates and InstantCloneSpec to be used to create an InstantClone
        :param spec:  a dictionary containing 3 keys: name, location, and config
                      name = the name of the new instant clone
                      location = a dict of relocation spec data
                      config = a dict of keys\values to be used for guest
                               customization
        :return: vim.vm.InstantCloneSpec object that can be used by
                 vm.InstantClone()
        """
        if not isinstance(spec, dict) and \
                ('name' and 'location' and 'config' not in spec):
            _ = 'instant clone spec must be a dict containing: name, location'
            _ += ', config'
            logger.warn(_)
        config = self.create_option_value(spec['config'])
        location = self.create_vm_relocate_spec(**spec['location'])

        return vim.vm.InstantCloneSpec(name=spec['name'], location=location,
                                       config=config)

    def create_instant_clone(self, parent_vm, spec):
        """
        Method to trigger an instant clone of VM
        :param parent_vm:
        :param spec:
        :return:
        """
        parent_vm = self.get_obj([vim.VirtualMachine], parent_vm)
        spec = self.create_vm_instant_clone_spec(spec)
        task = parent_vm.InstantClone(spec)
        return self.wait_for_task(task)

    def create_ovfmanager_import_spec_parameters(self, dc, entityName='',
                                                 diskProvisioning='thin',
                                                 **kwargs):
        """
        Parameters for deploying an OVF.
        :param entityName = The name to set on the entity (more precisely, on
                            the top-level vApp or VM of the entity) as it
                            appears in VI. If empty, the product name is
                            obtained from the ProductSection of the descriptor.
                            If that name is not specified, the ovf:id of the
                            top-level entity is used.
        :param hostSystem = The host to validate the OVF descriptor against, if
                            it cannot be deduced from the resource pool. The
                            privilege System.Read is required on the host.
        :param networkMapping = The mapping of network identifiers from the
                                descriptor to networks in the VI infrastructure.
                                The privilege Network.Assign is required on all
                                networks in the list.
        :param ipAllocationPolicy = The IP allocation policy chosen by the
                                    caller.See VAppIPAssignmentInfo .
        :param ipProtocol = The IP protocol chosen by the caller. See
                            VAppIPAssignmentInfo.
        :param propertyMapping = The assignment of values to the properties
                                 found in the descriptor. If no value is
                                 specified for an option, the default value from
                                 the descriptor is used.
        :param resourceMapping = The resource configuration for the created
                                 vApp. This can be used to distribute a vApp
                                 across multiple resource pools (and create
                                 linked children).
        :param diskProvisioning = An optional disk provisioning. If set, all the
                                  disks in the deployed OVF will have get the
                                  same specified disk type (e.g.,
                                  thin provisioned). The valid values for disk
                                  provisioning are:
                                    monolithicSparse,
                                    monolithicFlat,
                                    twoGbMaxExtentSparse,
                                    twoGbMaxExtentFlat,
                                    thin,
                                    thick,
                                    sparse,
                                    flat,
                                    seSparse

        :return: import spec
        """
        if 'networkMapping' in kwargs:
            """
            takes a list of dicts {'source': <net name>, 'target': <net name>}
            """
            nmaplist = kwargs.get('networkMapping')

            if not isinstance(nmaplist, list):
                logger.warn('networkMapping must be a list')
                return 1

            networkMapping = []

            for nmap in nmaplist:
                if not isinstance(nmap, dict):
                    logger.warn('networkMapping vales must be a dict')
                    return 1

                dcnets = {net.name: net for net in dc.network}
                if nmap['target'] not in dcnets.keys():
                    _ = "Target net {} not found in VI".format(nmap['target'])
                    logger.warn(_)
                    return 1

                networkMapping.append(vim.OvfManager.NetworkMapping(
                    name=nmap['source'], network=dcnets[nmap['target']]))

            kwargs['networkMapping'] = networkMapping

        m = 'not implemented in vsphere.py'
        m += ' create_ovfmanager_import_spec_parameters()!'

        if 'ipAllocationPolicy' in kwargs:
            logger.warn('ipAllocationPolicy {}'.format(m))

        if 'ipProtocol' in kwargs:
            logger.warn('ipProtocol {}'.format(m))

        if 'propertyMapping' in kwargs:
            pmap = kwargs.get('propertyMapping')
            if not isinstance(pmap, dict):
                _ = "CreateImportSpec params: propertyMapping must be a dict"
                logger.warn(_)
                return 1
            kwargs['propertyMapping'] = [vim.KeyValue(key=k, value=v)
                                         for k, v in pmap.iteritems()]

        if 'resourceMapping' in kwargs:
            logger.warn('resourceMapping {}'.format(m))

        return vim.OvfManager.CreateImportSpecParams(
            entityName=entityName, diskProvisioning=diskProvisioning, **kwargs)

    def deploy_ova(self, ova, importSpecParams=None, datacenter=None,
                   resource_pool=None, cluster=None, datastore=None):
        """
        Deploys an ova file to the current vi service instance.  This keyword
        doesn't require ovftool.

        :param ova:             REQUIRED:  Path to the OVA file, can be local or
                                           a URL.
        :param importSpecParams Dict of key value pairs needed to create
                                vim.OvfManager.CreateImportSpecParams. see
                                create_ovfmanager_import_spec_parameters.
                                If not provided, 'name' defaults to what is
                                specified in the ovf file, and '
                                diskProvisioning' type defaults to 'thin'.
        :param datacenter:      Name of datacenter to search on. Defaults to
                                first.
        :param resource_pool:   Name of resource pool to use. Defaults to
                                largest memory free.
        :param cluster:         Name of cluster to use. Defaults to the
                                resource_pool with the largest memory free.
        :param datastore:       Name of datastore to use. Defaults to largest
                                free space in datacenter.
        :return:
        Example:

        import_spec = {'propertyMapping': {'Hostname': 'plexxi.connect.rb',  # OS hostname
                                           'Domainname': 'rdlabs.hpecorp.net',
                                           'NTP1': 'ntp.hpecorp.net',
                                           'DHCP': 'True',
                                           'IP': '0.0.0.0',  # must be 0.0.0.0 if DHCP is true
                                           'Netmask': '255.255.255.0',
                                           'Gateway': '0.0.0.0',
                                           'DNS1': '',
                                           'DNS2': ''
                                           },
                          'entityName': 'Plexxi CFM',
                          'networkMapping': [{'source': 'VM Network',
                                              'target': 'Private'}]
                      }

        |  connect to vi server  |  15.245.130.50  |   root   | password |
        |  deploy ova            |  ova=c:\\PlexxiConnect-5.0.0-3065.ova|
                                    importSpecParams=${import_spec} | |
        or
        |  deploy ova            |  ova=http://<ip>/PlexxiConnect.ova| | |

        """
        try:
            si = self.service_instance

            if datacenter:
                dc = get_dc(si, datacenter)
            else:
                dc = si.content.rootFolder.childEntity[0]

            if datastore:
                ds = get_ds(dc, datastore)
            else:
                ds = get_largest_free_ds(dc)

            if resource_pool:
                rp = get_rp(si, dc, resource_pool)
            elif cluster:
                cluster_list = dc.hostFolder.childEntity
                cluster_obj = get_obj_in_list(cluster, cluster_list)
                rp = cluster_obj.resourcePool
            else:
                rp = get_largest_free_rp(si, dc)

            if importSpecParams is None:
                cisp = self.create_ovfmanager_import_spec_parameters(dc)
            elif isinstance(importSpecParams,
                            vim.OvfManager.CreateImportSpecParams):
                # already an CreateImportSpecParams object
                cisp = importSpecParams
            else:
                # treat as k\v pairs
                cisp = self.create_ovfmanager_import_spec_parameters(
                    dc, **importSpecParams)

            ovf_handle = OvfHandler(ova)

            ovfManager = si.content.ovfManager

            cisr = ovfManager.CreateImportSpec(ovf_handle.get_descriptor(),
                                               rp, ds, cisp)

            # These errors might be handleable by supporting the parameters in
            # CreateImportSpecParams
            if len(cisr.error):
                _ = "The following errors will prevent import of this OVA:"
                logger.info(_)
                for error in cisr.error:
                    logger.info(error)
                return 1

            ovf_handle.set_spec(cisr)

            lease = rp.ImportVApp(cisr.importSpec, dc.vmFolder)
            while lease.state == vim.HttpNfcLease.State.initializing:
                logger.info("Waiting for lease to be ready...")
                time.sleep(1)

            if lease.state == vim.HttpNfcLease.State.error:
                logger.info("Lease error: %s" % lease.error)
                return 1
            if lease.state == vim.HttpNfcLease.State.done:
                return 0

            logger.info("Starting deploy...")
            return ovf_handle.upload_disks(lease,
                                           self.service_instance._stub.host)

        except Exception as e:
            raise AssertionError("Failed to deploy OVA: {}".format(e))

    def deploy_ovf_ova_template(self, vc_ip, vc_user_name, vc_pwd, network,
                                vmname, templatelocation, datastore, vmhost,
                                resource_pool):
        """
        Deplpy VM from template
        Example:
        deploy ovf ova template | 172.25.111 | root | vmware | 172.25.8.* | VM1
                                | temp_fldr_name | datastore1 | host1 |rspool1
        """
        try:
            cmd = 'ovftool --powerOn -nw="{}"'.format(network)
            cmd += ' -n="{}" -ds="{}" "{}"'.format(vmname, datastore,
                                                   templatelocation)
            cmd += ' "vi://{}:{}@{}/?ip={}"'.format(vc_user_name, vc_pwd, vc_ip,
                                                    vmhost)
            exit_status = os.system(cmd)

            if not exit_status:
                logger.info(" %s successfully deployed" % vmname)
                self._migrate_vm(vmname, resource_pool)
            else:
                logger.warn(
                    "Failed to deploy template : %s for VM %s :" %
                    (templatelocation, vmname))
        except Exception as e:      # no-qa
            logger.warn('Failed to deploy due to exception :' + str(e))

    @staticmethod
    def deploy_ovf_ova_template_to_folder_in_cluster(vc_ip, vc_user_name,
                                                     vc_pwd, network, vmname,
                                                     templatelocation,
                                                     datastore, vmfolder,
                                                     vmdatacenter, vmcluster):
        """
        Deploy VM from template in specified folder
        Example:
        deploy ovf ova template to folder in cluster | 172.25.111 | root |
                                                       vmware | 172.25.8.* |
                                                       VM1 | temp_fldr_name |
                                                       datastore1 | automation |
                                                       DC1 | DC1_C1
        """
        try:
            cmd = 'ovftool --skipManifestCheck -dm=thin -n="{}"'.format(vmname)
            cmd += ' -ds="{}" -nw="{}" -vf="{}" "{}"'.format(datastore, network,
                                                             vmfolder,
                                                             templatelocation)
            cmd += ' "vi://{}:{}@{}/{}/host/{}"'.format(vc_user_name, vc_pwd,
                                                        vc_ip, vmdatacenter,
                                                        vmcluster)
            exit_status = os.system(cmd)
            if not exit_status:
                logger.info(" %s successfully deployed" % vmname)
            else:
                logger.warn(
                    "Failed to deploy template : %s for VM %s :" %
                    (templatelocation, vmname))
        except Exception as e:      # no-qa
            logger.warn('Failed to deploy due to exception :' + str(e))

    @staticmethod
    def download_ovf_ova(build_url, location, build_name):
        """
        Downloads ovf from specified path
        """
        file_name = os.path.splitext(build_name)[0]
        file_extension = os.path.splitext(build_name)[1]
        build_url_name = build_url + build_name
        ovf_ova_dwnld_loc = location + build_name
        # To remove the file if already exist to download the latest file
        if os.path.isfile(ovf_ova_dwnld_loc):
            os.remove(ovf_ova_dwnld_loc)
        try:
            urlobj = urllib2.urlopen(build_url_name)
            with open(ovf_ova_dwnld_loc, 'wb') as fp:
                shutil.copyfileobj(urlobj, fp)
        except Exception as e:
            logger._warn("Failed to download the latest build from URL : %s" %
                         build_url + " due to error" + str(e))

        if file_extension == '.ova':
            sig_filename = build_name + '.sig'
            md5_filename = build_name + '.md5'
            sig_filename_url = build_url + sig_filename
            md5_filename_url = build_url + md5_filename
            sig_dwnld_loc = location + sig_filename
            md5_dwnld_loc = location + md5_filename

            try:
                urlobj_sig = urllib2.urlopen(sig_filename_url)
                with open(sig_dwnld_loc, 'wb') as sig_fp:
                    shutil.copyfileobj(urlobj_sig, sig_fp)
                urlobj_md5 = urllib2.urlopen(md5_filename_url)
                with open(md5_dwnld_loc, 'wb') as md5_fp:
                    shutil.copyfileobj(urlobj_md5, md5_fp)
            except Exception as e:
                logger.warn(
                    "Failed to download the files from URL : %s and %s" %
                    (sig_filename_url, md5_filename_url) + " due to error" +
                    str(e))
        elif file_extension == '.ovf':
            mf_filename = file_name + '.mf'
            vmdk_filename = file_name + '-disk1.vmdk'
            mf_filename_url = build_url + mf_filename
            vmdk_filename_url = build_url + vmdk_filename
            mf_dwnld_loc = location + mf_filename
            vmdk_dwnld_loc = location + vmdk_filename

            try:
                urlobj_mf = urllib2.urlopen(mf_filename_url)
                with open(mf_dwnld_loc, 'wb') as mf_fp:
                    shutil.copyfileobj(urlobj_mf, mf_fp)
                urlobj_vmdk = urllib2.urlopen(vmdk_filename_url)
                with open(vmdk_dwnld_loc, 'wb') as vmdk_fp:
                    shutil.copyfileobj(urlobj_vmdk, vmdk_fp)
            except Exception as e:
                logger.warn(
                    "Failed to download the files from URL : %s and %s" %
                    (mf_filename_url, vmdk_filename_url) + " due to error" +
                    str(e))

        logger.info("Downloaded the build from %s to %s with status %s " %
                    (build_url_name, ovf_ova_dwnld_loc,
                     str(os.path.isfile(ovf_ova_dwnld_loc))))

        return os.path.isfile(ovf_ova_dwnld_loc)

    def enable_vmotion(self, host_name, cluster_name):
        """
        enables vmotion
        Example:
        enable vmotion | host1 | DC1_C1 |
        """
        host_obj = self._get_host(host_name)
        cluster_obj = self._get_cluster(cluster_name)
        ic = vim.host.IpConfig()
        nc = vim.host.VMotionSystem.NetConfig()
        vmotion_sys = vim.host.VMotionSystem(ic, nc)
        config_mgr = vim.host.ConfigManager()
        config_mgr.vmotionSystem = vmotion_sys
        host_obj.ConfigManager = config_mgr
        task = cluster_obj.MoveInto(host_obj)
        return self.wait_for_task(task)

    def reconfigure_ha(self, cluster_name, enable=True):
        """
        Enables or Disables the HA Configuration for Cluster name passed
        Waits until the task gets completed
        Example:
        Reconfigure ha | cluster_name | True
        :param cluster_name:
        :param enable:
        :return: Task status
        """
        cluster_obj = self._get_cluster(cluster_name)
        cluster_config_spec = vim.cluster.ConfigSpec()
        config = vim.cluster.DasConfigInfo()
        if enable:
            config.enabled = True
            config.hostMonitoring = 'enabled'
        else:
            config.enabled = False
            config.hostMonitoring = 'disabled'
        cluster_config_spec.dasConfig = config
        task = cluster_obj.ReconfigureCluster_Task(cluster_config_spec,
                                                   modify=True)
        return self.wait_for_task(task)

    def reconfigure_drs(self, cluster_name, enable=True):
        """
        Enables or Disables the DRS Configuration for Cluster name passed
        Waits until the task gets completed
        Example:
        Reconfigure drs | cluster_name | True
        :param cluster_name:
        :param enable:
        :return: Task status
        """
        cluster_obj = self._get_cluster(cluster_name)
        cluster_config_spec = vim.cluster.ConfigSpec()
        config = vim.cluster.DrsConfigInfo()
        config.enabled = enable
        cluster_config_spec.drsConfig = config
        task = cluster_obj.ReconfigureCluster_Task(cluster_config_spec,
                                                   modify=True)
        return self.wait_for_task(task)

    def get_host_vswitches(self, host=None):
        """
        Returns list of all the vswitches associated to the Host
        Example:
        Get Host vswitches     |host_name
        Returns : List of vswitches associated to the Host
        """
        host_obj = self.get_mor(host)
        if host_obj is None:
            raise AssertionError('Unable to find the host in Vcenter: {0}'.format(host))
        return [network.name for network in host_obj.config.network.vswitch]

    def get_host_vswitch_vmnics(self, host):
        """
        Returns list of all the Vmnics associated to Host Vswitch
        Example:
        Get Host vswitch vmnics     |host_name
        Returns : List of vmnics associated to the virtual switches
        """
        vmnics = []
        host_obj = self._get_host(host)
        for network in host_obj.config.network.vswitch:
            vmnics.append(network.spec.bridge.nicDevice[0])
        return vmnics

    def get_host_dvs_vmnics(self, host):
        """
        Returns list of all the Vmnics associated to Host Vswitch
        Example:
        Get Host dvs vmnics     |host_name
        Returns : List of vmnics associated to the Distributed switches
        """
        vmnics = []
        host_obj = self._get_host(host)
        for network in host_obj.config.network.proxySwitch:
            vmnics.append(network.spec.backing.pnicSpec[0].pnicDevice)
        return vmnics

    def get_host_vmnics(self, host):
        """
        Returns list of all the Vmnics from the host
        Example:
        Get Host vmnics     |host_name
        Returns : List of all vmnics present in the host
        """
        vswitch_vmnics = []
        host_obj = self._get_host(host)
        for pnic in host_obj.config.network.pnic:
            vswitch_vmnics.append(pnic.device)
        return vswitch_vmnics

    def add_vswitch_to_host(self, vswitch_name, num_ports, nic_device, *hosts):
        """
        Creates Standard switch on the host list specified
        Example:
            add vswitch to host   |vswitch_name |2 |10.1.1.x| pnic_name| Hosts
        :param vswitch_name:
        :param num_ports: Max 1024
        :param hosts:
        :param nic_device:
        :return:
        """
        hosts_obj = []
        for host in hosts:
            hosts_obj.append(self._get_host(host))

        for host in hosts_obj:
            host_network_system = host.configManager.networkSystem
            vss_spec = vim.host.VirtualSwitch.Specification()
            vss_spec.numPorts = int(num_ports)
            if nic_device:
                vss_spec.bridge = \
                    vim.host.VirtualSwitch.BondBridge(nicDevice=[nic_device])

            host_network_system.AddVirtualSwitch(vswitchName=vswitch_name,
                                                 spec=vss_spec)

    def create_port_group(self, host, pg_name, vss_name, vlan_id):
        """
        Creates Port group for standard switch
        Example:
            Create Port Group       | host_name| portgroup_name |
                                     virtual_switch_name | vlanId
        :param host:
        :param pg_name:
        :param vss_name: Should be added present in the HostSystem
        :return:
        """
        host_obj = self._get_host(host)
        host_network_system = host_obj.configManager.networkSystem
        port_group_spec = vim.host.PortGroup.Specification()
        port_group_spec.name = pg_name
        port_group_spec.vlanId = int(vlan_id)
        port_group_spec.vswitchName = vss_name
        security_policy = vim.host.NetworkPolicy.SecurityPolicy()
        security_policy.allowPromiscuous = True
        security_policy.forgedTransmits = True
        security_policy.macChanges = False
        port_group_spec.policy = \
            vim.host.NetworkPolicy(security=security_policy)
        host_network_system.AddPortGroup(portgrp=port_group_spec)

    def vswitch_should_exist(self, host, vswitch_name):
        """
        Vswitch Should Exist will return true if vswitch found
        Example:
        Vswitch Should Exist | host | vswitch_name|
        Returns: Raise Assertion error in case vswitch not found
        """
        host_obj = self._get_host(host)
        if not any(net.name == vswitch_name for net in host_obj.network):
            _ = 'VSwitch {} not found in {}'.format(vswitch_name, host)
            raise AssertionError(_)

    def vswitch_exists(self, host, vswitch_name):
        """
        Vswitch Exists will return true if vswitch found
        Example:
        Vswitch Exists | host | vswitch_name|
        Returns: True if vswitch exists
                 False if vswitch doesn't exists
        """
        host_obj = self._get_host(host)
        return any(net.name == vswitch_name for net in host_obj.network)

    def vswitch_does_not_exist(self, host, vswitch_name):
        """
        Vswitch does not exit will return true if vswitch_name not found
        Example:
        Vswitch Does Not Exist | host | vswitch_name|
        Returns: True if vswitch does not exists
                False if Vswitch exists
        """
        host_obj = self._get_host(host)
        return not any(net.name == vswitch_name for net in host_obj.network)

    def remove_vswitch(self, host, vswitch_name):
        """
        Remove Vswitch Returns None on successful completion of task, raises
        below Faults mentioned.
        Example:
        Remove vswitch | host | vswitch_name
        Return: None
        RemoveVirtualSwitch()  raises below errors on failure
        Faults :
        HostConfigFault    Thrown for all other configuration failures.
        NotFound    Thrown if the virtual network adapter cannot be found.
        RuntimeFault    Thrown if any type of runtime fault is thrown that is
                        not covered by the other faults; for example, a
                        communication error.
        """
        host_obj = self._get_host(host)
        host_network_system = host_obj.configManager.networkSystem
        host_network_system.RemoveVirtualSwitch(vswitch_name)

    def remove_cluster_datastore(self, host, storage_name):
        """
        Remove Cluster Datastore Returns None on successful completion of task,
        raises below Faults mentioned.
        Example:
        Remove Cluster Datastore | host| storage_name
        Return : None
        RemoveDatastore() raises below errors on failure
        Faults :
        DatastoreNotWritableOnHost    Thrown if the datastore argument is set
                                      and the host cannot write to the
                                      indicated datastore.
        InaccessibleDatastore    Thrown if the datastore argument is set and
                                 the host cannot access the indicated datastore.
        NotSupported    Thrown if the datastore argument is set and the
                        localSwapDatastoreSupported capability is not true for
                        the host.
        RuntimeFault    Thrown if any type of runtime fault is thrown that is
                        not covered by the other faults;
                        for example, a communication error.
        AssertionError    Thrown if the Datastore Doesnot exists for the host
        """
        host_obj = self._get_host(host)
        host_storage_system = host_obj.configManager.datastoreSystem
        if (ds.name == storage_name for ds in host_obj.datastore):
            host_storage_system.RemoveDatastore(storage_name)
        else:
            _ = "Host: {} does not have the data store: {}".format(host,
                                                                   storage_name)
            raise AssertionError(_)

    def datastore_should_exist(self, host, storage_name):
        """
        Datastore Should Exist will return true if datastore found
        Example:
        Datastore Should Exist | host | storage_name|
        Returns: Raise Assertion error in case datastore is not found
        """
        host_obj = self._get_host(host)
        if not any(ds.name == storage_name for ds in host_obj.datastore):
            _ = "Host: {} does not have the data store: {}".format(host,
                                                                   storage_name)
            raise AssertionError(_)

    def datastore_exists(self, host, storage_name):
        """
        Datastore Exists will return true if datastore found
        Example:
        Datastore Exists | host | storage_name|
        Returns: True if datastore exists
                 False if datastore doesn't exists
        """
        host_obj = self._get_host(host)
        return any(ds.name == storage_name for ds in host_obj.datastore)

    def datastore_does_not_exist(self, host, storage_name):
        """
        Datastore Does Not Exist will return true if datastore not found
        Example:
        Datastore Does Not Exist | host | storage_name|
        Returns: True if datastore doesn't exists
                 False if datastore exists
        """
        host_obj = self._get_host(host)
        return not any(ds.name == storage_name for ds in host_obj.datastore)

    def remove_vnic(self, host, vnic_name):
        """
        Remove Vnic Returns None on completion of task.
        Example:
        Remove Vnic |host | vnic_name|
        Return : None
        RemoveVirtualNic() raises below errors on failure
        Faults :
        HostConfigFault    Thrown for all other configuration failures.
        NotFound    Thrown if the virtual network adapter cannot be found.
        RuntimeFault    Thrown if any type of runtime fault is thrown that is
                         not covered by the other faults; for example,
                         a communication error.
        """
        host_obj = self._get_host(host)
        host_network_system = host_obj.configManager.networkSystem
        host_network_system.RemoveVirtualNic(vnic_name)

    def portgroup_should_exist(self, host, pg_name):
        """
        Portgroup Should Exists will return true if pg_name found
        Example:
        PortGroup Should Exist |host | pg_name|
        Returns: Raise Assertion error in case pg_name not found
        """
        host_obj = self._get_host(host)
        if not any(pg.spec.name == pg_name
                   for pg in host_obj.config.network.portgroup):
            _ = 'pg_name {} not found in {}'.format(pg_name, host)
            raise AssertionError(_)

    def portgroup_exists(self, host, pg_name):
        """
        Portgroup Exists will return true if pg_name found
        Example:
        PortGroup Exists |host | pg_name|
        Returns: True if PortGroup name exists
                 False If PortGroup doesn't exists
        """
        host_obj = self._get_host(host)
        return any(pg.spec.name == pg_name
                   for pg in host_obj.config.network.portgroup)

    def portgroup_does_not_exist(self, host, pg_name):
        """
        Portgroup Does Not Exists will return pg-name if found
        Example:
        PortGroup Does Not Exist |host | pg_name|
        Returns: True if PortGroup doesn't exists
                 False If PortGroup exists
        """
        host_obj = self._get_host(host)
        return not any(pg.spec.name == pg_name
                       for pg in host_obj.config.network.portgroup)

    def remove_portgroup(self, host, pg_name):
        """
        Remove portgroup Returns None on completion of task
        Example:
        Remove PortGroup |host | pg_name|
        Return : None
        RemovePortGroup() raises below errors on failure
        Faults :
        HostConfigFault    Thrown for all other configuration failures.
        NotFound    Thrown if the virtual network adapter cannot be found.
        ResourceInUse    Thrown if the port group can not be removed because
                         there are virtual network adapters associated with it.
        RuntimeFault    Thrown if any type of runtime fault is thrown that is
                        not covered by the other faults;
                        for example, a communication error.
        """
        host_obj = self._get_host(host)
        host_network_system = host_obj.configManager.networkSystem
        host_network_system.RemovePortGroup(pg_name)

    def rename_portgroup(self, host, pg_name, newname, virt_sw_name):
        """
        Rename portgroup Returns None on completion of task.
        Example:
        Rename Portgroup |host | pg_name|
        Return : None
        UpdatePortGroup() raises below errors on failure
        Faults :
        HostConfigFault	    Thrown for all other configuration failures.
        InvalidArgument	    Thrown if the PortGroup vlanId is invalid. Valid
                            vlanIds range from [0,4095], where 0 means no vlan
                            tagging. Exception is also thrown if network policy
                            is invalid.
        NotFound	        Thrown if the port group or virtual switch does
                            not exist.
        RuntimeFault	    Thrown if any type of runtime fault is thrown that
                            is not covered by the other faults;
                            for example, a communication error.
        """
        host_obj = self._get_host(host)
        host_network_system = host_obj.configManager.networkSystem
        port_group_spec = vim.host.PortGroup.Specification()
        port_group_spec.name = newname
        port_group_spec.vswitchName = virt_sw_name
        security_policy = vim.host.NetworkPolicy.SecurityPolicy()
        port_group_spec.policy = vim.host.NetworkPolicy(security=security_policy)
        host_network_system.UpdatePortGroup(pg_name, port_group_spec)

    def create_vmkernal_nic_on_std_switch(self, host, pg_name, mac=None,
                                          dhcp=True, ipAddress=None,
                                          subnetMask=None):
        """
        Creates vmkernal nic on standard switch
        :param host: host_name
        :param pg_name:    specify portgroup_name (type : str)
        :param mac:        accepts str type
        :param dhcp:       accepts boolean type
        :param ipAddress:  required if dhcp is false
        :param subnetMask: required if dhcp is false
        :return:  Returns the device name of the virtual network adapter as
                  type String
        Raises Assertion Error if portGroup doesn't exits on the switch

        Example :
        Create Vmkernal Nic On Std Switch   | Host | pg_name | mac | dhcp |
                                              ipAdresss |  subnetMask
        Create Vmkernal Nic On Std Switch   |'10.1.48.37' | 'portgroup_name'
        """
        host_obj = self._get_host(host)
        if self.portgroup_exists(host, pg_name):
            host_network_system = host_obj.configManager.networkSystem
            nic = vim.host.VirtualNic.Specification()
            nic.mac = mac
            ip = vim.host.IpConfig()
            ip.dhcp = dhcp
            if not dhcp:
                ip.ipAddess = ipAddress
                ip.subnetMask = subnetMask
            nic.ip = ip
            return host_network_system.AddVirtualNic(pg_name, nic)
        else:
            _ = "port group : {} does not exists on host : {}".format(pg_name,
                                                                      host)
            raise AssertionError(_)

    def enable_vmotion_service(self, host, vmk_name):
        """
        Enables Vmotion services on selected vmk adaptor
        :param vmk_name: specify vmkernal nic name (type : str)
        :return: None on successful enabling of the services

        Raises InvalidArgument Exception if vmk_name does not exists in the host

        Other possible exceptions thrown by SelectVnic Method are
        HostConfigFault:       Thrown for any other failure
        RuntimeFault:          Thrown if any type of runtime fault is thrown
                               that is not covered by the other faults;
                               for example, a communication error.
        Example:
        Enable Vmotion Service   |host | vmk3
        """
        host_obj = self._get_host(host)
        host_vmotion_system = host_obj.configManager.vmotionSystem
        host_vmotion_system.SelectVnic(vmk_name)

    def get_mor(self, name=None, obj=vim.HostSystem, flag=True):
        """
        Returns a starting point reference of the current configuration for the
        given object
        :param str name: Optional - name of the Managed Entity Object
        :param str obj: vim.Folder | vim.Datacenter | vim.ComputeResource |
                        vim.ResourcePool | vim.HostSystem
        :param bool flag: Retrieve child entities or not
        :return ManagedObjectReference: Reference object
        """
        view_mgr = self.content.viewManager
        try:
            ref = view_mgr.CreateContainerView(self.content.rootFolder,
                                               [obj], flag)
        except vmodl.RuntimeFault as e:
            logger.warn('A communication error has occurred')
            logger.debug('Traceback:\t{}'.format(e))
            return None

        try:
            if name is None and obj == vim.HostSystem and self.is_esxi():
                return ref.view[0] if len(ref.view) else None
            else:
                for h in ref.view:
                    if h.name == name:
                        return h

                # At this point no object reference was found
                return None
        finally:
            ref.Destroy()

    def is_vcenter(self):
        """
        Returns true if the connection is established to a vCenter Server
        :return: bool

        Example
          | ${status}=    | Is vCenter |
        """
        if 'VirtualCenter'.lower() in \
                str(self.content.about.licenseProductName).lower():
            return True

        return False

    def is_esxi(self):
        """
        Return true if the connection is established to a ESXi host
        :return: bool

        Example
          | ${status}=    | Is ESXi |
        """
        if 'ESX'.lower() in str(self.content.about.licenseProductName).lower():
            return True

        return False

    def datacenter_exists(self, name):
        """
        Returns true if the Datacenter exists in the vCenter
        :param str name: Name of datacenter
        :return bool: True if the datacenter exists else False
        """
        return True if self.get_mor(name, vim.Datacenter, True) else False

    def get_host_nic_names(self):
        """
        Returns a list of Physical Network Device names found in the host. This
        method is supported for ESXi systems only
        :return list: str
        """
        o = self.get_mor()
        return [pn.device for pn in o.config.network.pnic] if o else None

    def get_host_mac_addresses(self):
        """
        Returns a list of physical network device MAC address available in the
        host system. This method is for ESXi systems only
        :return list: str
        """
        o = self.get_mor()
        return [pn.mac for pn in o.config.network.pnic] if o else None

    def get_host_nic_name_mac(self):
        """
        Returns a dictionary having MAC as the key and device name as value for
        all physical network ports found in the ESXi system
        :return list: List of dictionary containing MAC, device name
        """
        o = self.get_mor()
        if o is None:
            return None

        r = dict()
        for p in o.config.network.pnic:
            r.update({p.mac.lower(): p.device.lower()})

        return r

    def get_vswitch_uplinks(self, name):
        """
        Returns the physical NIC port keys acting as uplinks for the given
        standard vSwtich
        :param str name: Name of the vSwitch
        :return list: List of physical NIC keys
        """
        o = self.get_mor()
        if o is None:
            return None

        for p in o.config.network.vswitch:
            if p.name == name:
                return [str(i).split('-')[-1] for i in p.pnic]

        return None

    def esx_vswitch_exists(self, name):
        """
        Checks if the virtual switch exists in the host
        :param str name: Name of the virtual switch
        :return bool: True if found else false
        """
        o = self.get_mor()
        if o:
            return any(s.name == name for s in o.config.network.vswitch)
        else:
            return False

    def get_vswitch_object(self, name):
        """
        Returns vim.host.VirtualSwitch data object
        :param str name: Name of the vSwitch
        :return: vim.host.VritualSwitch
        """
        o = self.get_mor()

        for s in o.config.network.vswitch:
            if name.lower() == s.name.lower():
                return s

        return None

    @staticmethod
    def _get_link_discovery_spec(spec):
        """
        Returns a reference to the Link Discovery Protocol Configuration
        :param spec: key-value pair that has operation & protocol keys
        :return: Reference to vim.host.LinkDiscoveryProtocolConfig
        """
        s = vim.host.LinkDiscoveryProtocolConfig()
        s.operation = spec.get('operation', 'listen')
        s.protocol = spec.get('protocol', 'cdp')

        return s

    def _get_bridge_specs(self, **kwargs):
        """
        Returns a references to the virtual switch bridge specification
        :param kwargs: Key value pairs that are supported is
                       nics - <list> of NIC names
                       bridge - {'operation': '', 'protocol': '', 'beacon':}
        :return: Reference to vim.host.VirtualSwitch.BondBridge
        """
        spec = vim.host.VirtualSwitch.BondBridge()
        spec.nicDevice = kwargs.get('nics')
        spec.linkDiscoveryProtocolConfig = \
            self._get_link_discovery_spec(kwargs.get('bridge', dict()))

        if len(spec.nicDevice) > 1 and 'beacon' in kwargs:
            spec.beacon = vim.host.VirtualSwitch.BeaconConfig()
            spec.beacon.interval = kwargs.get('beacon')

        return spec

    @staticmethod
    def _get_teaming_policy(spec, nics=None):
        """
        Returns a reference to Nic teaming policy object
        :param spec: Supported keys are failower, active, standby, notify,
                     policy, rolling
        :param list nics: List of network ports
        :return: Reference to vim.
        """
        pol = vim.host.NetworkPolicy.NicTeamingPolicy()
        allowed_policy = ['loadbalance_ip', 'loadbalance_srcmac',
                          'loadbalance_srcid', 'failover_explicit']

        if spec.get('policy', 'loadbalance_srcid') in allowed_policy:
            pol.policy = spec.get('policy', 'loadbalance_srcid')
        else:
            pol.policy = 'loadbalance_srcid'
            logger.debug('Invalid Network teaming policy provided')
            logger.debug('Valid policies are \t{}'.format(allowed_policy))
            logger.info('Route based on originating port ID is set')

        pol.failureCriteria = vim.host.NetworkPolicy.NicFailureCriteria()
        pol.failureCriteria.checkBeacon = spec.get('failover', False)

        # Fixme: The below are depreciated attributes in VI API 5.1 however
        # it is still required
        pol.failureCriteria.checkSpeed = 'minimum'
        pol.failureCriteria.speed = 10
        pol.failureCriteria.checkDuplex = False
        pol.failureCriteria.fullDuplex = False
        pol.failureCriteria.checkErrorPercent = False
        pol.failureCriteria.percentage = 0

        pol.notifySwitches = spec.get('notify', True)
        pol.rollingOrder = spec.get('rolling', True)
        pol.reversePolicy = True

        pol.nicOrder = vim.host.NetworkPolicy.NicOrderPolicy()
        pol.nicOrder.activeNic = spec.get('active', nics)
        pol.nicOrder.standbyNic = spec.get('standby', None)

        return pol

    @staticmethod
    def _get_security_policy(cfg):
        """
        Returns a reference to network security policy
        :param cfg: Supported keys are promiscuous, forged_transmits, mac_change
        :return: Reference to vim.host.NetworkPolicy.SecurityPolicy
        """
        spec = vim.host.NetworkPolicy.SecurityPolicy()
        spec.allowPromiscuous = cfg.get('promiscuous', False)
        spec.forgedTransmits = cfg.get('forged_transmits', True)
        spec.macChanges = cfg.get('mac_changes', True)

        return spec

    @staticmethod
    def _get_shaping_policy(cfg):
        """
        Returns a reference to the network traffic shaping policy
        :param cfg: Supported keys are avg_bandwidth, burst_size, enabled,
                                       peak_bandwidth
        :return:
        """
        spec = vim.host.NetworkPolicy.TrafficShapingPolicy()
        spec.enabled = cfg.get('enabled', False)
        spec.averageBandwidth = cfg.get('avg_bandwidth', 100000)
        spec.peakBandwidth = cfg.get('peak_bandwidth', 100000)
        spec.burstSize = cfg.get('burst_size', 102400)

        return spec

    def _get_network_policy(self, **kwargs):
        """
        Returns a reference to host network policy
        :param kwargs: Supported keys are team, security, shaping
        :return: Reference to vim.host.NetworkPolicy
        """
        spec = vim.host.NetworkPolicy()
        spec.nicTeaming = self._get_teaming_policy(kwargs.get('team', {}),
                                                   kwargs.get('nics', None))
        spec.security = self._get_security_policy(kwargs.get('security', {}))
        spec.shapingPolicy = self._get_shaping_policy(kwargs.get('shaping', {}))

        return spec

    def add_standard_vswitch(self, name, **kwargs):
        """
        Adds a virtual standard switch to the host
        :param str name: Name of the switch
        :param kwargs: Key-value pairs... supported keys are
                            host - name of the host
                            mtu - Maximum transmission unit
                            ports - Number of ports
                            nics - List of uplink ports
                            bridge - {'operation': advertise, listen, both
                                                   or none,
                                      'protocol': 'cdp' or 'lldp',
                                      'beacon': <int>}
                            team - {'failover': True | False,
                                    'active': <list> of NICs,
                                    'standby': <list> of NICs,
                                    'notify': True | False,
                                    'policy': loadbalance_ip |
                                              loadbalance_srcmac |
                                              loadbalance_srcid |
                                              failover_explict ,
                                    'rolling': True | False }
                            security - {'promiscuous': True | False,
                                        'forged_transmits: True | False,
                                        'mac_changes': True | False}
                            shaping - { 'avg_bandwidth': <long>,
                                        'burst_size': <long>,
                                        'enabled': True | False,
                                        'peak_bandwidth': <long> }
        Usage:
          | ${status}= | Add Standard vSwitch | <name> |
          | ${status}= | Add Standard vSwitch | <name> | mtu=1500 | port=8 |

        :return bool: True on success else False
        """
        if 'host' in kwargs and self.is_vcenter():
            ref = self.get_mor(name=kwargs.get('host'))
        else:
            ref = self.get_mor()

        if ref is None:
            return False

        cfg_ref = ref.configManager.networkSystem

        if kwargs:
            spec = vim.host.VirtualSwitch.Specification()
            spec.numPorts = kwargs.get('ports', 8)
            spec.mtu = kwargs.get('mtu', 1500)
            spec.policy = self._get_network_policy(**kwargs)

            if 'nics' in kwargs and kwargs.get('nics') >= 1:
                spec.bridge = self._get_bridge_specs(**kwargs)
        else:
            spec = None

        try:
            if spec:
                cfg_ref.AddVirtualSwitch(vswitchName=name, spec=spec)
            else:
                cfg_ref.AddVirtualSwitch(vswitchName=name)
        except (vim.fault.AlreadyExists, vim.fault.HostConfigFault,
                vmodl.fault.InvalidArgument, vim.fault.ResourceInUse,
                vmodl.RuntimeFault) as e:
            logger.warn('ERROR: Unable to create virtual switch')
            logger.debug('TRACEBACK:\t{}'.format(e))
            return False

        return True

    def add_portgroup_to_vswitch(self, switch_name, pg_name, **kwargs):
        """
        Adds a PortGroup to a given virtual standard switch
        :param str switch_name: Name of standard vSwitch
        :param str pg_name: Name of the portgroup to be added
        :param kwargs: Supported keys are
                        host - name of the ESXi host
                        vlan - VLAN identifier
                        team - {'failover': True | False,
                                'active': <list> of NICs,
                                'standby': <list> of NICs,
                                'notify': True | False,
                                'policy': loadbalance_ip |
                                          loadbalance_srcmac |
                                          loadbalance_srcid |
                                          failover_explict ,
                                'rolling': True | False }
                        security - {'promiscuous': True | False,
                                    'forged_transmits: True | False,
                                    'mac_changes': True | False}
                        shaping - { 'avg_bandwidth': <long>,
                                    'burst_size': <long>,
                                    'enabled': True | False,
                                    'peak_bandwidth': <long> }
        :return bool: True on success else false
        """
        if 'host' in kwargs and self.is_vcenter():
            ref = self.get_mor(name=kwargs.get('host'))
        else:
            ref = self.get_mor()

        if ref is None:
            return False

        cfg_ref = ref.configManager.networkSystem

        spec = vim.host.PortGroup.Specification()
        spec.name = pg_name
        spec.vswitchName = switch_name
        spec.vlanId = kwargs.get('vlan', 0)
        spec.policy = self._get_network_policy(**kwargs)

        try:
            cfg_ref.AddPortGroup(spec)
        except (vim.fault.AlreadyExists, vim.fault.HostConfigFault,
                vmodl.fault.InvalidArgument, vmodl.RuntimeFault,
                vim.fault.NotFound) as e:
            logger.warn('ERROR: Unable to add portgroup to vSwitch')
            logger.debug('TRACEBACK:\t{}'.format(e))
            return False

        return True

    def get_portgroups_in_vswitch(self, name=None):
        """
        Returns a list of PortGroups part of the provided vSwitch name
        configured VLAN for the given virtual
        :param str name: Name of the switch
        :return list: List of all configured portgroups in the vSwitch
        """
        o = self.get_mor()

        if o is None:
            return None

        if name:
            return [pg.spec.name for pg in o.config.network.portgroup
                    if name in pg.vswitch] if self.esx_vswitch_exists(name) \
                else None
        else:
            return [pg.spec.name for pg in o.config.network.portgroup]

    def _get_ip_spec(self, dhcp=True, ipv4=None, subnet=None):
        """
        Returns the IpConfig data object
        :param bool dhcp: True for IP addresses provided by DHCP service
        :param str ipv4: IPv4 notation
        :param str subnet: sub network mask
        :return: vim.host.IpConfig
        """
        spec = vim.host.IpConfig()
        spec.dhcp = dhcp

        if not dhcp:
            spec.ipAddress = ipv4
            spec.subnetMask = subnet

        return spec

    def _get_nic_spec(self, dhcp=True, ipv4=None, subnet=None,
                      stack='defaultTcpipStack'):
        """
        Returns a specification of HostVirtualNic based on the inputs provided
        :param stack: type of service 'defaultTcpip' | 'vmotion' |
                                      'vSphereProvisioning'
        :param bool dhcp: True for IP address provided by DHCP service
        :param str ipv4: Ipv4 notation
        :param str subnet: Sub network mask
        :return vim.host.VirtualNic.Specification: object
        """
        spec = vim.host.VirtualNic.Specification()

        stack_set = ['defaultTcpipStack', 'vmotion', 'vSphereProvisioning']
        spec.netStackInstanceKey = stack if stack in stack_set else stack_set[0]
        spec.ip = self._get_ip_spec(dhcp, ipv4, subnet)

        return spec

    def add_nic_to_vswitch(self, **kwargs):
        """
        Adds a Virtual NIC to the specified portgroup
        :param dict kwargs: Supported keys are
                                portgroup - Required, name of the PG
                                dhcp      - Required, bool True for DHCP
                                ipv4      - IPv4 notation address
                                subnet    - subnet mask
                                stack     - Type of TCP/IP stack
                                type      - type of services
                                host      - name of the host system
        :return bool: True if the NIC is added successfully else False
        """
        if 'portgroup' not in kwargs or 'dhcp' not in kwargs:
            logger.debug('Missing required keys: portgroup or dhcp')
            return False

        if 'host' in kwargs and self.is_vcenter():
            ref = self.get_mor(name=kwargs.get('host'))
        else:
            ref = self.get_mor()

        if ref is None:
            return False

        cfg_ref = ref.configManager.networkSystem

        try:
            logger.debug('Creating virtualNIC with spec {}'.format(kwargs))
            n = cfg_ref.AddVirtualNic(kwargs.get('portgroup'),
                                      self._get_nic_spec(kwargs.get('dhcp'),
                                                         kwargs.get('ipv4'),
                                                         kwargs.get('subnet'),
                                                         kwargs.get('stack')))
            logger.debug('vmkernel port created successfully')

            nic_type = None
            if 'fault' in kwargs.get('type').lower():
                nic_type = 'faultToleranceLogging'
            elif 'management' in kwargs.get('type').lower():
                nic_type = 'management'
            elif 'vmotion' in kwargs.get('type').lower() and \
                    kwargs.get('stack').lower() != 'vmotion':
                # If stack is vmotion then service is configured as vMotion
                nic_type = 'vmotion'

            if nic_type:
                logger.debug('Adding service type to vmkernel port')
                n_ref = ref.configManager.virtualNicManager
                n_ref.SelectVnicForNicType(nic_type, n)
                logger.debug('Add vnic type {} to vmkernel'.format(nic_type))

        except (vim.fault.AlreadyExists, vim.fault.HostConfigFault,
                vmodl.fault.InvalidArgument, vim.fault.InvalidState,
                vmodl.RuntimeFault) as e:
            logger.warn('Encountered an error during vmkernel addition')
            logger.debug('Traceback:\t{}'.format(e))
            return False

        return True

    def vswitch_add_uplinks(self, name, ports):
        """
        Adds the list of ports to the provided standard virtual switch. The list
        of ports can be device name or MAC addresses. It can contain list of
        ports that are already acting as uplinks to the same switch
        :param str name: vSwitch name
        :param list ports: List of ports to be added as uplinks
        :return bool: True if successful else false
        """
        # Retrieve vSwitch specification
        vswitch_obj = self.get_vswitch_object(name)
        if vswitch_obj is None:
            logger.warn('Unable to retrieve vSwitch configuration information')
            return False

        device_list = self.get_host_nic_name_mac()
        uplinks_cfg = [str(i).split('-')[-1] for i in vswitch_obj.pnic]
        uplinks = list()

        for port in ports:
            if port.count(':') == 5 and device_list.get(port.lower()):
                uplinks.append(device_list[port.lower()])
            else:
                uplinks.append(port)

        # Add existing uplinks with the new ones
        add_ports = list(set(uplinks + uplinks_cfg))
        if add_ports == uplinks_cfg:
            logger.debug('Nothing to do as uplinks are already configured')
            return True

        if not len(vswitch_obj.pnic):
            vswitch_obj.spec.bridge = self._get_bridge_specs(nics=add_ports)
        else:
            vswitch_obj.spec.bridge.nicDevice = add_ports

        # By default, making the ports as active
        vswitch_obj.spec.policy.nicTeaming.nicOrder.activeNic = add_ports

        try:
            cfg_ref = self.get_mor().configManager.networkSystem
            cfg_ref.UpdateVirtualSwitch(name, vswitch_obj.spec)
        except (vim.fault.HostConfigFault, vmodl.fault.InvalidArgument,
                vim.fault.NotFound, vmodl.fault.NotSupported,
                vim.fault.ResourceInUse, vmodl.RuntimeFault) as e:
            logger.warn('ERROR: Unable to add uplinks to the vswitch')
            logger.debug('Traceback:\t{}'.format(e))
            return False

        return True

    def get_LatestBuild_name(self, build_url, image_type,
                             regexp_image_url=r"HPE?OneView.*.%s$"):
        """
        Downloads the last build
        :param build_url:
        :param location:
        :param image_type:
        :param regexp_image_url:
        :return:
        """

        def embedded_numbers(str_with_num):
            """    @Author: John"""
            re_digits = re.compile(r'(\d+)')
            # Split to digit and non-digit
            pieces = re_digits.split(str_with_num)
            # Convert digit to int
            pieces[1::2] = map(int, pieces[1::2])
            return pieces[1::2]

        def sort_strings_with_embedded_numbers(alist, reverse=False):
            """
            Sort the list that the elements have numbers embedded.
            @Author: John
            """
            return sorted(alist, key=embedded_numbers, reverse=reverse)

        try:
            image_urls = self.parse_url(url=build_url,
                                        pattern=regexp_image_url % image_type,
                                        timeout=60)
            target_image_url = None

            if image_urls:
                image_urls = sort_strings_with_embedded_numbers(image_urls,
                                                                reverse=True)

                for item in image_urls:
                    if "PASS" not in item:
                        # if 'PASS' not in item.split('/')[-1]:
                        if not re.search(r'PASS', item.split('/')[-1]):
                            target_image_url = item
                            break
                    else:  # non_pass = False
                        # if 'PASS' in item.split('/')[-1]:
                        if re.search(r'PASS', item.split('/')[-1]):
                            target_image_url = item
                            break

            else:
                _ = "The processed image list is empty, Please check web page"
                _ += ' {}'.format(build_url)
                raise Exception(_)
            if not target_image_url:
                _ = "Failed to get the latest build name from URL:"
                _ += ' {}'.format(build_url)
                raise Exception()
            else:
                return target_image_url
        except Exception as e:      # no-qa
            _ = "Failed to get the latest build name from URL:"
            _ += ' {} {}'.format(build_url, str(e))

            raise Exception(_)

    class URLLister(SGMLParser):
        """
        Parsing the html page
        """

        def reset(self):
            """
            Method to reset the listener
            :return:
            """
            SGMLParser.reset(self)
            self.urls = []

        def start_a(self, attrs):
            """
            Call during a begin of 'a' tag element
            :param attrs:
            :return:
            """
            href = [v for k, v in attrs if k == 'href']
            if href:
                self.urls.extend(href)

    def parse_url(self, url=None, pattern=None, timeout=60):
        """
        Pars url and return the result into a list.
        """
        try:
            tgt_urls = []
            response = urllib2.urlopen(url, timeout=timeout)
            parser = self.URLLister()
            parser.feed(response.read())
            parser.close()
            for i in parser.urls:
                if re.search(pattern, i):
                    tgt_urls.append(i)
            return tgt_urls
        except Exception as e:
            logger.warn('Unreachable Link: %s' % url + " " + str(e))
            return None

    def get_list_of_file_names(self, build_url, file_type):
        """
        Get the list of file which ends with FILE_TYPE |rpm|txt|zip|
        """
        try:
            logger.info("Build URL provided: {}".format(build_url))
            rpm_urls = self.parse_url(url=build_url,
                                      pattern=".*" + file_type + "$",
                                      timeout=60)

            if rpm_urls:
                return rpm_urls
            else:
                _ = "The processed rpm list is empty, Please check web page"
                _ += ' }!'.format(build_url)
                raise Exception(_)

        except Exception as e:
            _ = "Failed to get the rpms from URL : %s" % build_url + str(e)
            raise Exception(_)


def get_dc(si, name):
    """
    Get a datacenter by its name.
    """
    for dc in si.content.rootFolder.childEntity:
        if dc.name == name:
            return dc
    raise Exception('Failed to find datacenter named %s' % name)


def get_rp(si, dc, name):
    """
    Get a resource pool in the datacenter by its names.
    """
    view_manager = si.content.viewManager
    containerView = view_manager.CreateContainerView(dc, [vim.ResourcePool],
                                                     True)
    try:
        for rp in containerView.view:
            if rp.name == name:
                return rp
    finally:
        containerView.Destroy()
    raise Exception("Failed to find resource pool %s in datacenter %s" %
                    (name, dc.name))


def get_largest_free_rp(si, dc):
    """
    Get the resource pool with the largest unreserved memory for VMs.
    """
    view_manager = si.content.viewManager
    container_view = view_manager.CreateContainerView(dc, [vim.ResourcePool],
                                                      True)
    largest_rp = None
    unreserved_for_vm = 0
    try:
        for rp in container_view.view:
            if rp.runtime.memory.unreservedForVm > unreserved_for_vm:
                largest_rp = rp
                unreserved_for_vm = rp.runtime.memory.unreservedForVm
    finally:
        container_view.Destroy()

    if largest_rp is None:
        raise Exception("Failed to find a resource pool in dc %s" % dc.name)
    return largest_rp


def get_ds(dc, name):
    """
    Pick a datastore by its name.
    """
    for ds in dc.datastore:
        try:
            if ds.name == name:
                return ds
        except:  # no-qa
            pass
    raise Exception("Failed to find %s on datacenter %s" % (name, dc.name))


def get_obj_in_list(obj_name, obj_list):
    """
    Gets an object out of a list (obj_list) whos name matches obj_name.
    """
    for o in obj_list:
        if o.name == obj_name:
            return o
    _ = "Unable to find object by the name of %s in list:\n%s" % (
        o.name, map(lambda o: o.name, obj_list))
    raise Exception()


def get_largest_free_ds(dc):
    """
    Pick the datastore that is accessible with the largest free space.
    """
    largest = None
    largest_free = 0
    for ds in dc.datastore:
        try:
            free_space = ds.summary.freeSpace
            if free_space > largest_free and ds.summary.accessible:
                largest_free = free_space
                largest = ds
        except:  # no-qa
            pass

    if largest is None:
        raise Exception('Failed to find any free datastores on %s' % dc.name)

    return largest


def get_tarfile_size(archive):
    """
    Determine the size of a file inside the tarball.
    If the object has a size attribute, use that. Otherwise seek to the end
    and report that.
    """
    if hasattr(archive, 'size'):
        return archive.size
    size = archive.seek(0, 2)
    archive.seek(0, 0)
    return size


class OvfHandler(object):
    """
    OvfHandler handles most of the OVA operations.
    It processes the tarfile, matches disk keys to files and
    uploads the disks, while keeping the progress up to date for the lease.
    """

    def __init__(self, ovafile):
        """
        Performs necessary initialization, opening the OVA file,
        processing the files and reading the embedded ovf file.
        """
        self.handle = self._create_file_handle(ovafile)
        self.tarfile = tarfile.open(fileobj=self.handle)
        ovffilename = list(filter(lambda x: x.endswith(".ovf"),
                                  self.tarfile.getnames()))[0]
        ovffile = self.tarfile.extractfile(ovffilename)
        self.descriptor = ovffile.read().decode()

    def _create_file_handle(self, entry):
        """
        A simple mechanism to pick whether the file is local or not.
        This is not very robust.
        """
        if os.path.exists(entry):
            return FileHandle(entry)
        else:
            return WebHandle(entry)

    def get_descriptor(self):
        """
        Returns the object descriptor
        :return:
        """
        return self.descriptor

    def set_spec(self, spec):
        """
        The import spec is needed for later matching disks keys with
        file names.
        """
        self.spec = spec

    def get_disk(self, file_item):
        """
        Does translation for disk key to file name, returning a file handle.
        """
        ovffilename = list(filter(lambda x: x == file_item.path,
                                  self.tarfile.getnames()))[0]
        return self.tarfile.extractfile(ovffilename)

    def get_device_url(self, file_item, lease):
        """
        Method to retrieve the device URL
        :param fileItem:
        :param lease:
        :return:
        """
        for deviceUrl in lease.info.deviceUrl:
            if deviceUrl.importKey == file_item.deviceId:
                return deviceUrl
        raise Exception("Failed to find deviceUrl for file %s" % file_item.path)

    def upload_disks(self, lease, host):
        """
        Uploads all the disks, with a progress keep-alive.
        """
        self.lease = lease

        try:
            self.start_timer()
            for fileItem in self.spec.fileItem:
                self.upload_disk(fileItem, lease, host)
            lease.Complete()
            logger.info("Finished deploy successfully.")
            return 0
        except vmodl.MethodFault as e:
            logger.info("Hit an error in upload: %s" % e)
            lease.Abort(e)
        except Exception as e:
            logger.info("Lease: %s" % lease.info)
            logger.info("Hit an error in upload: %s" % e)
            lease.Abort(vmodl.fault.SystemError(reason=str(e)))
            raise
        return 1

    def upload_disk(self, fileItem, lease, host):
        """
        Upload an individual disk. Passes the file handle of the
        disk directly to the urlopen request.
        """
        ovffile = self.get_disk(fileItem)
        if ovffile is None:
            return

        device_url = self.get_device_url(fileItem, lease)
        url = device_url.url.replace('*', host)
        headers = {'Content-length': get_tarfile_size(ovffile)}
        if hasattr(ssl, '_create_unverified_context'):
            sslContext = ssl._create_unverified_context()
        else:
            sslContext = None
        req = Request(url, ovffile, headers)
        urlopen(req, context=sslContext)

    def start_timer(self):
        """
        A simple way to keep updating progress while the disks are transferred.
        """
        Timer(5, self.timer).start()

    def timer(self):
        """
        Update the progress and reschedule the timer if not complete.
        """
        try:
            prog = self.handle.progress()
            self.lease.Progress(prog)
            if self.lease.state not in [vim.HttpNfcLease.State.done,
                                        vim.HttpNfcLease.State.error]:
                self.start_timer()
            sys.stderr.write("Progress: %d%%\r" % prog)
        except:  # no-qa
            pass


class FileHandle(object):
    """
    Object referencing a file
    """

    def __init__(self, filename):
        """
        Object initialization method
        :param filename:
        """
        self.filename = filename
        self.fh = open(filename, 'rb')

        self.st_size = os.stat(filename).st_size
        self.offset = 0

    def __del__(self):
        """
        Destructor call during garbbage collection
        :return:
        """
        self.fh.close()

    def tell(self):
        """
        Current handler position
        :return:
        """
        return self.fh.tell()

    def seek(self, offset, whence=0):
        """
        Method to move to a specified point
        :param offset:
        :param whence:
        :return:
        """
        if whence == 0:
            self.offset = offset
        elif whence == 1:
            self.offset += offset
        elif whence == 2:
            self.offset = self.st_size - offset

        return self.fh.seek(offset, whence)

    def seekable(self):
        """
        Method to confirm iteration
        :return:
        """
        return True

    def read(self, amount):
        """
        Retrieves a chuck of data
        :param amount:
        :return:
        """
        self.offset += amount
        result = self.fh.read(amount)
        return result

    # A slightly more accurate percentage
    def progress(self):
        """
        Method to provided the currect progress
        :return:
        """
        return int(100.0 * self.offset / self.st_size)


class FileNotFoundError(Exception):
    """
    Exception object class
    """
    pass


class WebHandle(object):
    """
    Object referencing the webpage
    """

    def __init__(self, url):
        """
        Initialization method
        :param url:

        """
        self.url = url
        if '@' in self.url:   # Assume basic auth if there is an @ in url
            password_mgr = HTTPPasswordMgrWithDefaultRealm()
            at = url.rfind("@")  # Need the LAST @, some usernames have an @ in them
            slashes = url.find("//")
            creds = url[slashes + 2:at]
            user = creds[:creds.find(":")]
            passw = creds[creds.find(":") + 1:]
            newurl = url[:slashes + 2] + url[at + 1:]
            password_mgr.add_password(None, newurl, user, passw)
            handler = HTTPBasicAuthHandler(password_mgr)
            opener = build_opener(handler)
            install_opener(opener)
            self.url = newurl
        r = urlopen(self.url)
        if r.code != 200:
            raise FileNotFoundError(url)
        self.headers = self._headers_to_dict(r)
        if 'accept-ranges' not in self.headers:
            raise Exception("Site does not accept ranges")
        self.st_size = int(self.headers['content-length'])
        self.offset = 0

    def _headers_to_dict(self, r):
        """
        Returns the URL header section in Dictionary format
        :param r:
        :return:
        """
        result = {}
        if hasattr(r, 'getheaders'):
            for n, v in r.getheaders():
                result[n.lower()] = v.strip()
        else:
            for line in r.info().headers:
                if line.find(':') != -1:
                    n, v = line.split(': ', 1)
                    result[n.lower()] = v.strip()
        return result

    def tell(self):
        """
        Retrieves the current position
        :return:
        """
        return self.offset

    def seek(self, offset, whence=0):
        """
        Method to move to a specific position
        :param offset:
        :param whence:
        :return:
        """
        if whence == 0:
            self.offset = offset
        elif whence == 1:
            self.offset += offset
        elif whence == 2:
            self.offset = self.st_size - offset
        return self.offset

    def seekable(self):
        """
        Method that determines if the handle can be moved
        :return:
        """
        return True

    def read(self, amount):
        """
        Retrieves the data from the current position
        :param amount:
        :return:
        """
        start = self.offset
        end = self.offset + amount - 1
        req = Request(self.url,
                      headers={'Range': 'bytes=%d-%d' % (start, end)})
        r = urlopen(req)
        self.offset += amount
        result = r.read(amount)
        r.close()
        return result

    # A slightly more accurate percentage
    def progress(self):
        """
        Returns the current state.
        :return:
        """
        return int(100.0 * self.offset / self.st_size)
